{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tasks with Kinematic Time Series from Head-Mounted Displays\n",
    "\n",
    "## **Load and preprocess datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File Path: d:\\dsv\\dev\\git_repos\\headmov-classif-360videos/\n"
     ]
    }
   ],
   "source": [
    "# Add files to sys.path\n",
    "from pathlib import Path\n",
    "import sys,os\n",
    "this_path = None\n",
    "try:\n",
    "    this_path = str(os.path.dirname(__file__)) #str(Path().absolute())+\"/\" # str(os.path.dirname(__file__))\n",
    "except:\n",
    "    this_path = str(Path().absolute())+\"/\" #str(Path().absolute())+\"/\" # str(os.path.dirname(__file__))\n",
    "print(\"File Path:\", this_path)\n",
    "sys.path.append(os.path.join(this_path, \"kinemats\"))\n",
    "\n",
    "# Enable debugger in IPython with command set_trace()\n",
    "#from IPython.core.debugger import set_trace\n",
    "\n",
    "# Import classes\n",
    "import utils  # Utils for generation of files and paths\n",
    "\n",
    "from data_loader import dataset_ucr,\\\n",
    "                        dataset_IMT,\\\n",
    "                        dataset_Tsinghua\n",
    "\n",
    "from data_loader.dataset_IMT import VideoList\n",
    "\n",
    "# Import data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.rcParams['text.usetex'] = True\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "---\n",
    "# SETUP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "import experiment_config\n",
    "from experiment_config import Datasets\n"
   ]
  },
  {
   "source": [
    "---\n",
    "# UTILITY FUNCTIONS\n",
    "\n",
    "Generate paths to write output files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tsinghua/\n"
     ]
    }
   ],
   "source": [
    "STR_DATASET = str(experiment_config.DATASET_MAIN)+\"/\"\n",
    "print(STR_DATASET)\n",
    "def gen_path_plot(filename):\n",
    "    # Generates full paths for PLOTS just by specifying a name\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.PLOT_FOLDER, \\\n",
    "                                        subfolders=STR_DATASET+NOTEBOOK_SUBFOLDER_NAME, \\\n",
    "                                        file_extension=experiment_config.IMG_FORMAT, save_files=experiment_config.EXPORT_PLOTS)\n",
    "\n",
    "def gen_path_temp(filename, subfolders=\"\", extension=experiment_config.TEMP_FORMAT):\n",
    "    # Generates full paths for TEMP FILES just by specifying a name\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.TEMP_FOLDER, \\\n",
    "                                        subfolders=STR_DATASET+subfolders, \\\n",
    "                                        file_extension=extension)\n",
    "\n",
    "def gen_path_dataset(filename, subfolders=\"\", extension=\"\"):\n",
    "    # Generates full paths for RESULTS FILES (like pandas dataframes)\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.DATASET_FOLDER, \\\n",
    "                                        subfolders=STR_DATASET+subfolders, \\\n",
    "                                        file_extension=extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess datasets"
   ]
  },
  {
   "source": [
    "# 1. Dataset UCR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if experiment_config.DATASET_MAIN == Datasets.UCR:\n",
    "#     # keep_sets define whether merging or not the training and test set.\n",
    "#     d = data_loader.dataset_ucr.load_ucr_dataset(\"UWaveGestureLibrary\", keep_sets=True, root_folder = \"dataset/UCR/\", suffix_folders = [\"X\",\"Y\",\"Z\"], sets = [\"TRAIN\",\"TEST\"], file_format = \".tsv\", missing_val = 0)\n",
    "\n",
    "#     for el in d:\n",
    "#         print(el.shape)"
   ]
  },
  {
   "source": [
    "# 2. Dataset Head Movements IMT\n",
    "\n",
    "File from http://dash.ipv6.enstb.fr/headMovements/ and paper in http://doi.org/10.1145/3083187.3083215\n",
    "\n",
    "## Extract data from Tar file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.IMT:\n",
    "    # Original compressed dataset\n",
    "    dataset_path = experiment_config.DATASET_IMT_TAR\n",
    "    # Path of JSON dictionary used to store the data per user\n",
    "    dict_json_name = gen_path_temp('files_index_per_user', extension=\".json\")\n",
    "\n",
    "    # Class with all file manipulation for the dataset IMT\n",
    "    data = dataset_IMT.DatasetHeadMovIMT(dataset_path,dict_json_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.IMT:\n",
    "    # Filename of the file containing demographics and HMD movements data\n",
    "    general_data_filename = experiment_config.DATASET_DEMOGRAPHICS\n",
    "    movement_data_filename= gen_path_temp(\"hmd_movements\", extension=\".pickle\")\n",
    "\n",
    "    # Initial number of users is 63. Data from 5 users was removed due to missing \n",
    "    # values in main videos. Total size is 58. Moreover, videos used for \n",
    "    # familiarizing users with VR were deleted: `VideoList.Elephant` and `VideoList.Rhino`\n",
    "    skip_users_indices = [14, 33, 52, 61, 62]\n",
    "    videos_to_delete = [VideoList.Elephant, VideoList.Rhino]\n",
    "\n",
    "\n",
    "    ### INPUTS / OUTPUTS\n",
    "    \"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "    input_files = [general_data_filename, movement_data_filename]\n",
    "\n",
    "    RELOAD_TRIES = experiment_config.RELOAD_TRIES\n",
    "    # Try to load files maximum two times\n",
    "    for tries in range(RELOAD_TRIES):\n",
    "        try:\n",
    "            ### LOAD FILE\n",
    "            print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "            \n",
    "            ### CUSTOM SECTION TO READ FILES\n",
    "            \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "            data.general = pd.read_csv(input_files[0]) # data.general is a pd.DataFrame\n",
    "            print(f\"File {input_files[0]} was successfully loaded\")\n",
    "            data.movement = utils.load_pickle(input_files[1]) # data.movement is a Dictionary\n",
    "            print(f\"File {input_files[1]} was successfully loaded\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            ### CREATE FILE\n",
    "            print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "            ### CUSTOM SECTION TO CREATE FILES \n",
    "            \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "            # Create JSON with dictionary of structured data\n",
    "            data.generate_file_index()\n",
    "            # Load JSON\n",
    "            files_index = utils.load_json(dict_json_name)\n",
    "            print(\"Number of users in file index:\", len(files_index.keys()))\n",
    "            # Transform the paths in the compressed file into bytes\n",
    "            data.uncompress_data(files_index,\n",
    "                                    #debug_users = 15,                      # Load just this users for test purposes\n",
    "                                    list_unprocessed_users = skip_users_indices     # Users ID with empty data\n",
    "                                )\n",
    "\n",
    "            # Delete head-movement data of specific video keys\n",
    "            data.delete_data_from_videos(videos_to_delete)\n",
    "            print(\"Removing data from specific video keys... Done!\")\n",
    "\n",
    "            # Save files\n",
    "            data.general.to_csv(input_files[0], index=False)\n",
    "            utils.create_pickle(data.movement, input_files[1])\n",
    "\n",
    "            ### ---- CONTROL RETRIES\n",
    "            if tries+1 < RELOAD_TRIES:\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        break"
   ]
  },
  {
   "source": [
    "# 3. Tsinghua"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.Tsinghua:\n",
    "\n",
    "    # Original compressed dataset\n",
    "    dataset_path = experiment_config.DATASET_TSINGHUA_ZIP\n",
    "    # Path of JSON dictionary used to store the data per user\n",
    "    dict_json_name = gen_path_temp('files_index_per_user', extension=\".json\")\n",
    "\n",
    "    data = dataset_Tsinghua.DatasetHeadMovTsinghua(dataset_path, dict_json_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trying 1/2 to load files: ['./dataset/Tsinghua/demographics.csv', './temp/Tsinghua/hmd_movements.pickle']\n",
      "File not found. Creating again! [Errno 2] File b'./dataset/Tsinghua/demographics.csv' does not exist: b'./dataset/Tsinghua/demographics.csv'\n",
      "JSON file was created in ./temp/Tsinghua/files_index_per_user.json\n",
      "Loading... 1\n",
      "Loading... 10\n",
      "Loading... 11\n",
      "Loading... 12\n",
      "Loading... 13\n",
      "Loading... 14\n",
      "Loading... 15\n",
      "Loading... 16\n",
      "Loading... 17\n",
      "Loading... 18\n",
      "Loading... 19\n",
      "Loading... 2\n",
      "Loading... 20\n",
      "Loading... 21\n",
      "Loading... 22\n",
      "Loading... 23\n",
      "Loading... 24\n",
      "Loading... 25\n",
      "Loading... 26\n",
      "Loading... 27\n",
      "Loading... 28\n",
      "Loading... 29\n",
      "Loading... 3\n",
      "Loading... 30\n",
      "Loading... 31\n",
      "Loading... 32\n",
      "Loading... 33\n",
      "Loading... 34\n",
      "Loading... 35\n",
      "Loading... 36\n",
      "Loading... 37\n",
      "Loading... 38\n",
      "Loading... 39\n",
      "Loading... 4\n",
      "Loading... 40\n",
      "Loading... 41\n",
      "Loading... 42\n",
      "Loading... 43\n",
      "Loading... 44\n",
      "Loading... 45\n",
      "Loading... 46\n",
      "Loading... 47\n",
      "Loading... 48\n",
      "Loading... 5\n",
      "Loading... 6\n",
      "Loading... 7\n",
      "Loading... 8\n",
      "Loading... 9\n",
      "Loading... 1\n",
      "Loading... 10\n",
      "Loading... 11\n",
      "Loading... 12\n",
      "Loading... 13\n",
      "Loading... 14\n",
      "Loading... 15\n",
      "Loading... 16\n",
      "Loading... 17\n",
      "Loading... 18\n",
      "Loading... 19\n",
      "Loading... 2\n",
      "Loading... 20\n",
      "Loading... 21\n",
      "Loading... 22\n",
      "Loading... 23\n",
      "Loading... 24\n",
      "Loading... 25\n",
      "Loading... 26\n",
      "Loading... 27\n",
      "Loading... 28\n",
      "Loading... 29\n",
      "Loading... 3\n",
      "Loading... 30\n",
      "Loading... 31\n",
      "Loading... 32\n",
      "Loading... 33\n",
      "Loading... 34\n",
      "Loading... 35\n",
      "Loading... 36\n",
      "Loading... 37\n",
      "Loading... 38\n",
      "Loading... 39\n",
      "Loading... 4\n",
      "Loading... 40\n",
      "Loading... 41\n",
      "Loading... 42\n",
      "Loading... 43\n",
      "Loading... 44\n",
      "Loading... 45\n",
      "Loading... 46\n",
      "Loading... 47\n",
      "Loading... 48\n",
      "Loading... 5\n",
      "Loading... 6\n",
      "Loading... 7\n",
      "Loading... 8\n",
      "Loading... 9\n",
      "Trying 2/2 to load files: ['./dataset/Tsinghua/demographics.csv', './temp/Tsinghua/hmd_movements.pickle']\n",
      "File ./dataset/Tsinghua/demographics.csv was successfully loaded\n",
      "File ./temp/Tsinghua/hmd_movements.pickle was successfully loaded\n"
     ]
    }
   ],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.Tsinghua:\n",
    "    # Filename of the file containing demographics and HMD movements data\n",
    "    demographics_data_filename = experiment_config.DATASET_DEMOGRAPHICS\n",
    "    original_data_filename= gen_path_temp(\"hmd_movements\", extension=\".pickle\")\n",
    "\n",
    "\n",
    "    ### INPUTS / OUTPUTS\n",
    "    \"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "    input_files = [demographics_data_filename, original_data_filename]\n",
    "\n",
    "    RELOAD_TRIES = experiment_config.RELOAD_TRIES\n",
    "    # Try to load files maximum two times\n",
    "    for tries in range(RELOAD_TRIES):\n",
    "        try:\n",
    "            ### LOAD FILE\n",
    "            print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "            \n",
    "            ### CUSTOM SECTION TO READ FILES\n",
    "            \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "            data.demographics = pd.read_csv(input_files[0]) # data.general is a pd.DataFrame\n",
    "            print(f\"File {input_files[0]} was successfully loaded\")\n",
    "            data.original_data = utils.load_pickle(input_files[1]) # data.movement is a Dictionary\n",
    "            print(f\"File {input_files[1]} was successfully loaded\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            ### CREATE FILE\n",
    "            print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "            ### CUSTOM SECTION TO CREATE FILES \n",
    "            \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "            # Create JSON with dictionary of structured data\n",
    "            data.generate_file_index()\n",
    "            # Transform the paths in the compressed file into bytes\n",
    "            data.uncompress_data(#debug_users = 15,                      # Load just this users for test purposes\n",
    "                                 #list_unprocessed_users = skip_users_indices     # Users ID with empty data\n",
    "                                )\n",
    "\n",
    "            # # Delete head-movement data of specific video keys\n",
    "            # data.delete_data_from_videos(videos_to_delete)\n",
    "            # print(\"Removing data from specific video keys... Done!\")\n",
    "\n",
    "            # Save files\n",
    "            data.demographics.to_csv(input_files[0], index=False)\n",
    "            utils.create_pickle(data.original_data, input_files[1])\n",
    "\n",
    "            ### ---- CONTROL RETRIES\n",
    "            if tries+1 < RELOAD_TRIES:\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        break"
   ]
  },
  {
   "source": [
    "---\n",
    "## Data Synchronization with data interpolation {COMMON FOR ALL DATASETS}\n",
    "***Generate CSV file with summary of sampling frequency and duration***: The CSV file defines the criteria to resample all time series in common length."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trying 1/2 to load files: ['./dataset/Tsinghua/summary_timeseries.csv']\n",
      "File not found. Creating again! [Errno 2] File b'./dataset/Tsinghua/summary_timeseries.csv' does not exist: b'./dataset/Tsinghua/summary_timeseries.csv'\n",
      "Trying 2/2 to load files: ['./dataset/Tsinghua/summary_timeseries.csv']\n",
      "File ./dataset/Tsinghua/summary_timeseries.csv was successfully loaded\n",
      "   experiment  user  video  startingTime  endTime      N   magQuat  \\\n",
      "0           0     1      0         1.247  164.203  14726  1.000005   \n",
      "1           0     1      1         0.000  201.141  18180  0.999997   \n",
      "2           0     1      2         0.021  293.239  26272  1.000006   \n",
      "3           0     1      3         0.000  172.577  15478  0.999998   \n",
      "4           0     1      4         0.021  205.708  18443  1.000005   \n",
      "\n",
      "   avTsampling  avFsampling  \n",
      "0     0.011066    90.367952  \n",
      "1     0.011064    90.384357  \n",
      "2     0.011161    89.598865  \n",
      "3     0.011150    89.687502  \n",
      "4     0.011153    89.665365  \n"
     ]
    }
   ],
   "source": [
    "# Filename of the file containing demographics and HMD movements data\n",
    "sampling_stats_filename = experiment_config.DATASET_SUMMARY # Original sampling stats\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [sampling_stats_filename]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        sampling_stats = pd.read_csv(input_files[0]) # data.general is a pd.DataFrame\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "        # Summary of original sampling frequencies\n",
    "        sampling_stats = data.create_original_sampling_summary()\n",
    "        sampling_stats.to_csv(input_files[0], index=False)\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    break\n",
    "\n",
    "print(sampling_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLERP (Spherical Linear Interpolation)\n",
    "\n",
    "Slerp is shorthand for spherical linear interpolation. It refers to constant-speed motion along a unit-radius great circle arc, given the ends and an interpolation parameter. \"A major appeal is that interpolation is carried out as a rotation about a fixed axis at constant angular velocity\" [REF,pg.18](http://web.cs.iastate.edu/~cs577/handouts/quaternion.pdf)\n",
    "\n",
    "Let $p_{0}$ and $p_{1}$ be the first and last points in the arc, let $t$ be the parameter where $0 \\le t \\le 1$. Compute $\\Omega$ as the angle subtended by the arc so that $cos \\Omega = p_{0} \\cdot p_{1}$\n",
    "\n",
    "$Slerp(p_{0},p_{1};t) = \\frac{sin[(1-t)\\Omega]}{sin(\\Omega)}\\cdot p_{0} + \\frac{sin(t\\Omega)}{sin(\\Omega)}\\cdot p_{1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.IMT:\n",
    "    SAMPLING_FREQUENCY = 30\n",
    "    STARTING_TIME_SECS = 5\n",
    "    ENDING_TIME_SECS = 35\n",
    "elif experiment_config.DATASET_MAIN == Datasets.Tsinghua:\n",
    "    SAMPLING_FREQUENCY = 30\n",
    "    STARTING_TIME_SECS = 35\n",
    "    ENDING_TIME_SECS = 155\n",
    "\n",
    "    EXPERIMENT_ID = 0 # 0: Experiment_1: No instructions to look at video ROI >> 1: Experiment_2: Instruction to focus on video ROI;;; Check dataset paper for description "
   ]
  },
  {
   "source": [
    "This interpolation is common for both"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trying 1/2 to load files: ['./temp/IMT/hmd_movements_resampled.pickle']\n",
      "File not found. Creating again! [Errno 2] No such file or directory: './temp/IMT/hmd_movements_resampled.pickle'\n",
      "Each numpy array will be resampled to 901 samples. Timestamps from 5 to 35 seconds\n",
      "USER: 0 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 0 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 0 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 0 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 0 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 1 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 1 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 1 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 1 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 1 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 2 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 2 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 2 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 2 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 2 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 3 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 3 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 3 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 3 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 3 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 4 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 4 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 4 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 4 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 4 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 5 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 5 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 5 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 5 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 5 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 6 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 6 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 6 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 6 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 6 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 7 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 7 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 7 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 7 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 7 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 8 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 8 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 8 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 8 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 8 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 9 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 9 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 9 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 9 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 9 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 10 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 10 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 10 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 10 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 10 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 11 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 11 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 11 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 11 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 11 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 12 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 12 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 12 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 12 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 12 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 13 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 13 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 13 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 13 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 13 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 14 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 14 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 14 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 14 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 14 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 15 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 15 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 15 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 15 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 15 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 16 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 16 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 16 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 16 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 16 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 17 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 17 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 17 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 17 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 17 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 18 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 18 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 18 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 18 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 18 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 19 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 19 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 19 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 19 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 19 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 20 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 20 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 20 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 20 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 20 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 21 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 21 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 21 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 21 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 21 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 22 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 22 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 22 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 22 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 22 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 23 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 23 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 23 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 23 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 23 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 24 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 24 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 24 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 24 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 24 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 25 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 25 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 25 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 25 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 25 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 26 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 26 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 26 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 26 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 26 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 27 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 27 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 27 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 27 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 27 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 28 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 28 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 28 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 28 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 28 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 29 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 29 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 29 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 29 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 29 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 30 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 30 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 30 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 30 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 30 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 31 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 31 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 31 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 31 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 31 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 32 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 32 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 32 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 32 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 32 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 33 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 33 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 33 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 33 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 33 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 34 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 34 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 34 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 34 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 34 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 35 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 35 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 35 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 35 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 35 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 36 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 36 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 36 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 36 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 36 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 37 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 37 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 37 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 37 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 37 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 38 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 38 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 38 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 38 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 38 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 39 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 39 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 39 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 39 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 39 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 40 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 40 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 40 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 40 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 40 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 41 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 41 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 41 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 41 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 41 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 42 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 42 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 42 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 42 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 42 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 43 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 43 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 43 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 43 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 43 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 44 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 44 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 44 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 44 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 44 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 45 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 45 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 45 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 45 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 45 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 46 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 46 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 46 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 46 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 46 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 47 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 47 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 47 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 47 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 47 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 48 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 48 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 48 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 48 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 48 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 49 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 49 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 49 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 49 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 49 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 50 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 50 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 50 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 50 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 50 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 51 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 51 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 51 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 51 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 51 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 52 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 52 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 52 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 52 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 52 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 53 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 53 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 53 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 53 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 53 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 54 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 54 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 54 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 54 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 54 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 55 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 55 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 55 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 55 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 55 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 56 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 56 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 56 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 56 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 56 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 57 VIDEO: Diving | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 57 VIDEO: Paris | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 57 VIDEO: Rollercoaster | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 57 VIDEO: Timelapse | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "USER: 57 VIDEO: Venice | NEW SHAPE: (901, 5) idx_resampled 901\n",
      "Trying 2/2 to load files: ['./temp/IMT/hmd_movements_resampled.pickle']\n",
      "File ./temp/IMT/hmd_movements_resampled.pickle was successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# Structure with resampled time-series\n",
    "movement_resampled_data_filename = gen_path_temp(\"hmd_movements_resampled\", extension=\".pickle\")\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [movement_resampled_data_filename]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        data.processed = utils.load_pickle(input_files[0]) \n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "        \n",
    "        \n",
    "        if experiment_config.DATASET_MAIN == Datasets.IMT:\n",
    "            data.resample_movement(sampling_frequency = SAMPLING_FREQUENCY, starting_time = STARTING_TIME_SECS, end_time = ENDING_TIME_SECS)\n",
    "        elif experiment_config.DATASET_MAIN == Datasets.Tsinghua:\n",
    "            data.resample_movement(experiment_id = EXPERIMENT_ID, sampling_frequency = SAMPLING_FREQUENCY, starting_time = STARTING_TIME_SECS, end_time = ENDING_TIME_SECS)\n",
    "\n",
    "        # Create pickle file with resampled head-movement data\n",
    "        utils.create_pickle(data.processed, input_files[0])\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    break"
   ]
  },
  {
   "source": [
    "## Validate that interpolation is working properly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(901, 4)\n(901, 5)\n[5.         5.03333333 5.06666667 5.1        5.13333333 5.16666667\n 5.2        5.23333333 5.26666667 5.3       ]\n[5.         5.03333333 5.06666667 5.1        5.13333333 5.16666667\n 5.2        5.23333333 5.26666667 5.3       ]\n"
     ]
    }
   ],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.IMT: # Validate visually interpolation in some users\n",
    "    userId = 7\n",
    "    video = VideoList.Rollercoaster # VideoList.Paris, VideoList.Rollercoaster\n",
    "\n",
    "    # Extract user from original and resampled datasets\n",
    "    data_orig = data.get_movement_filtered(userId, video, column_to_filter=0, min_value=STARTING_TIME_SECS, max_value=ENDING_TIME_SECS)\n",
    "    data_orig = np.delete(data_orig, 1, axis=1) # Exclude the frameId column\n",
    "    data_processed = data.processed[userId][video.value]\n",
    "    print(data_orig.shape)\n",
    "    print(data_processed.shape)\n",
    "\n",
    "    print(data_orig[:10,0])\n",
    "    print(data_processed[:10,0])\n",
    "\n",
    "    # Plot time series\n",
    "    if False:\n",
    "        fig, axes = plt.subplots(1, 2, facecolor='w', edgecolor='k', sharex=True, sharey=True, figsize=(12, 4))\n",
    "\n",
    "        ax = axes[0]\n",
    "        ax.plot(data_orig[:,0], data_orig[:,1:],'-')\n",
    "        ax.set(xlabel=\"Elapsed video - Time (s)\", ylabel=\"Quaternion\", title=\"Original\")\n",
    "\n",
    "        ax = axes[1]\n",
    "        ax.plot(data_processed[:,0], data_processed[:,1:],'--')\n",
    "        ax.set(xlabel=\"Elapsed video - Time (s)\", ylabel=\"Quaternion\", title=\"Resampled\")\n",
    "\n",
    "        plt.suptitle('Visual inspection to resampling process')\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "source": [
    "## Create dataset in structured format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of users 58\nTotal number of videos per user 5\nTotal number of time series 290\nHead movement per video has size: (901, 5)\n"
     ]
    }
   ],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.IMT: # Validate visually interpolation in some users\n",
    "    # Summary of resampled head movement data\n",
    "    num_users = len(data.processed[:])\n",
    "    videos_per_user = len(data.processed[0].keys())\n",
    "    total_trajectories = num_users * videos_per_user\n",
    "    video_data_rows, video_data_cols = data.processed[0][str(VideoList.Diving)].shape\n",
    "\n",
    "    print(\"Total number of users\",num_users)\n",
    "    print(\"Total number of videos per user\",videos_per_user)\n",
    "    print(\"Total number of time series\", total_trajectories )\n",
    "    print(\"Head movement per video has size:\", (video_data_rows, video_data_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trying 1/2 to load files: ['./dataset/IMT/labels.csv', './dataset/IMT/timestamps.csv', './dataset/IMT/dataset.npy']\n",
      "File not found. Creating again! [Errno 2] File b'./dataset/IMT/labels.csv' does not exist: b'./dataset/IMT/labels.csv'\n",
      "Cluster index created at ./dataset/IMT/labels.csv\n",
      "Timestamps created at ./dataset/IMT/timestamps.csv\n",
      "Head movement resampled created at ./dataset/IMT/dataset.npy\n",
      "Trying 2/2 to load files: ['./dataset/IMT/labels.csv', './dataset/IMT/timestamps.csv', './dataset/IMT/dataset.npy']\n",
      "File ./dataset/IMT/labels.csv was successfully loaded\n",
      "File ./dataset/IMT/timestamps.csv was successfully loaded\n",
      "File ./dataset/IMT/dataset.npy was successfully loaded\n"
     ]
    }
   ],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.IMT: # Validate visually interpolation in some users\n",
    "    # Data for combined time series to cluster\n",
    "    labels_filename = experiment_config.DATASET_LABELS # Cluster index TRUE_LABEL\n",
    "    timestamps_filename = experiment_config.DATASET_TIMESTAMPS # Timestamps\n",
    "    dataset_filename = experiment_config.DATASET_DATA # Resampled data stats\n",
    "\n",
    "    # Load or create dataframe with statistics of initial dataset (58 users, 5 videos)\n",
    "    labels = None\n",
    "    timestamps = None\n",
    "    dataset = None\n",
    "\n",
    "    ### INPUTS / OUTPUTS\n",
    "    \"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "    input_files = [labels_filename, timestamps_filename, dataset_filename]\n",
    "\n",
    "    # Try to load files maximum two times\n",
    "    for tries in range(RELOAD_TRIES):\n",
    "        try:\n",
    "            ### LOAD FILE\n",
    "            print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "            \n",
    "            ### CUSTOM SECTION TO READ FILES\n",
    "            \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "            labels = pd.read_csv(input_files[0])\n",
    "            print(f\"File {input_files[0]} was successfully loaded\")\n",
    "            timestamps = np.loadtxt(input_files[1])\n",
    "            print(f\"File {input_files[1]} was successfully loaded\")\n",
    "            dataset = utils.load_binaryfile_npy(input_files[2])\n",
    "            print(f\"File {input_files[2]} was successfully loaded\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            ### CREATE FILE\n",
    "            print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "            ### CUSTOM SECTION TO CREATE FILES \n",
    "            \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "            ## Create DataFrame with labels\n",
    "            labels_cols = [\"id\",\"user\",\"videoId\"]\n",
    "            labels = np.empty((total_trajectories, len(labels_cols)))\n",
    "\n",
    "            # All time series are resampled with the same timestamps, just pick one!\n",
    "            timestamps = data.processed[0][VideoList.Paris.value][:,0]\n",
    "\n",
    "            # Contains all the trajectories in array,\n",
    "            dataset = np.empty((total_trajectories, video_data_rows, video_data_cols - 1))  ## The timestamp is in a different array\n",
    "            \n",
    "            # Convert the enum of the videos to an index\n",
    "            videolist_converter = {\n",
    "                                    VideoList.Diving.value: 1, \n",
    "                                    VideoList.Paris.value: 2, \n",
    "                                    VideoList.Rollercoaster.value: 3, \n",
    "                                    VideoList.Timelapse.value: 4, \n",
    "                                    VideoList.Venice.value: 5, }\n",
    "\n",
    "            # Time series index, used to map them back the original series with their respective user and index.\n",
    "            ts_idx = 0 \n",
    "            # Put together all the structured time series in one numpy array to do distance calculations\n",
    "            for user in range(num_users): #[0,1]:\n",
    "                for video in data.processed[user].keys():\n",
    "                    ## CHECK THAT ALL THE QUATERNIONS IN THE VIDEO HAVE MAGNITUDE 1. [Unit Quaternions]\n",
    "                    magnitudes = [np.linalg.norm(data.processed[user][video][row,1:]) for row in range(data.processed[user][video].shape[0])]\n",
    "                    [print(\"Quaternion norm not equal 1+/-0.01\",val, \"user:\", user, \"video\", video, \"row\", i) for i,val in enumerate(magnitudes) if (val > 1.01 or val < 0.99)]\n",
    "\n",
    "                    # Index of which time series corresponded to which video and which user\n",
    "                    labels[ts_idx] = [ts_idx, user, videolist_converter[video]]\n",
    "\n",
    "                    # Copy the original structured data in two np array with all the trajectories, offset of one sample\n",
    "                    dataset[ts_idx,:,:] = data.processed[user][video][:,1:] ## SKIP LAST SAMPLE\n",
    "\n",
    "                    # Time-series Index, combining the structure per user, per video.\n",
    "                    ts_idx += 1\n",
    "\n",
    "            ## SAVE FILES\n",
    "            # Create dataframe with time index\n",
    "            labels = pd.DataFrame(data=labels, columns=labels_cols)\n",
    "            labels.to_csv(input_files[0], index=False)\n",
    "            print(\"Cluster index created at\", input_files[0])\n",
    "\n",
    "            # Save timestamps\n",
    "            np.savetxt(input_files[1], timestamps, fmt='%f') # Supress scientific notation\n",
    "            print(\"Timestamps created at\",input_files[1])\n",
    "\n",
    "            # Create pickle file with combined time-series for clustering\n",
    "            utils.save_binaryfile_npy(dataset, input_files[2])\n",
    "            print(\"Head movement resampled created at\", input_files[2])\n",
    "\n",
    "\n",
    "            ### ---- CONTROL RETRIES\n",
    "            if tries+1 < RELOAD_TRIES:\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Finish iteration\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary data structure of Dataset 1: IMT\n",
    "\n",
    "**NOT VERY USEFUL**\n",
    "- `data.general` is a `pd.DataFrame`\n",
    "- `data.movement[0]` = returns a dictionary for the userid `0` with keys `{'video_id': <ndarray>}`,`video_id` is got automatically from the Enum `VideoList`\n",
    "- `data.movement[0][VideoList.Paris.value]` = returns a ndarray with hmd movement for a specific user and specific video\n",
    "- `data.processed[0][VideoList.Paris.value]` = returns a ndarray after applying the resampling\n",
    "\n",
    "**MOST USEFUL**\n",
    "- The files `labels`, `timestamps`, and `dataset` are used to load the structured dataset in any other data processing file.\n",
    "\n",
    "See example below:"
   ]
  },
  {
   "source": [
    "# 3. Dataset Tsinghua\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.Tsinghua: # Validate visually interpolation in some users\n",
    "    # Summary of resampled head movement data\n",
    "    num_users = len(data.processed.keys())\n",
    "    videos_per_user = len(data.processed[1].keys())\n",
    "    total_trajectories = num_users * videos_per_user\n",
    "    video_data_rows, video_data_cols = data.processed[1][0].shape\n",
    "\n",
    "    print(\"Total number of users\",num_users)\n",
    "    print(\"Total number of videos per user\",videos_per_user)\n",
    "    print(\"Total number of time series\", total_trajectories )\n",
    "    print(\"Head movement per video has size:\", (video_data_rows, video_data_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.Tsinghua: # Validate visually interpolation in some users\n",
    "    # Data for combined time series to cluster\n",
    "    labels_filename = experiment_config.DATASET_LABELS # Cluster index TRUE_LABEL\n",
    "    timestamps_filename = experiment_config.DATASET_TIMESTAMPS # Timestamps\n",
    "    dataset_filename = experiment_config.DATASET_DATA # Resampled data stats\n",
    "\n",
    "    # Load or create dataframe with statistics of initial dataset (58 users, 5 videos)\n",
    "    labels = None\n",
    "    timestamps = None\n",
    "    dataset = None\n",
    "\n",
    "    ### INPUTS / OUTPUTS\n",
    "    \"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "    input_files = [labels_filename, timestamps_filename, dataset_filename]\n",
    "\n",
    "    # Try to load files maximum two times\n",
    "    for tries in range(RELOAD_TRIES):\n",
    "        try:\n",
    "            ### LOAD FILE\n",
    "            print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "            \n",
    "            ### CUSTOM SECTION TO READ FILES\n",
    "            \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "            labels = pd.read_csv(input_files[0])\n",
    "            print(f\"File {input_files[0]} was successfully loaded\")\n",
    "            timestamps = np.loadtxt(input_files[1])\n",
    "            print(f\"File {input_files[1]} was successfully loaded\")\n",
    "            dataset = utils.load_binaryfile_npy(input_files[2])\n",
    "            print(f\"File {input_files[2]} was successfully loaded\")\n",
    "\n",
    "        except Exception as e:\n",
    "            ### CREATE FILE\n",
    "            print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "            ### CUSTOM SECTION TO CREATE FILES \n",
    "            \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "            ## Create DataFrame with labels\n",
    "            labels_cols = [\"id\",\"user\",\"videoId\"]\n",
    "            labels = np.empty((total_trajectories, len(labels_cols)))\n",
    "\n",
    "            # All time series are resampled with the same timestamps, just pick one!\n",
    "            timestamps = data.processed[1][0][:,0]\n",
    "\n",
    "            # Contains all the trajectories in array,\n",
    "            dataset = np.empty((total_trajectories, video_data_rows, video_data_cols - 1))  ## The timestamp is in a different array\n",
    "            \n",
    "            # Time series index, used to map them back the original series with their respective user and index.\n",
    "            ts_idx = 0 \n",
    "            # Put together all the structured time series in one numpy array to do distance calculations\n",
    "            for user in range(1,num_users+1): #[0,1]: ### USERS exist in original data from from 1-48, not 0-47\n",
    "                for video in data.processed[user].keys():\n",
    "                    ## CHECK THAT ALL THE QUATERNIONS IN THE VIDEO HAVE MAGNITUDE 1. [Unit Quaternions]\n",
    "                    magnitudes = [np.linalg.norm(data.processed[user][video][row,1:]) for row in range(data.processed[user][video].shape[0])]\n",
    "                    [print(\"Quaternion norm not equal 1+/-0.01\",val, \"user:\", user, \"video\", video, \"row\", i) for i,val in enumerate(magnitudes) if (val > 1.01 or val < 0.99)]\n",
    "\n",
    "                    # Index of which time series corresponded to which video and which user\n",
    "                    labels[ts_idx] = [ts_idx, user, video]\n",
    "\n",
    "                    # Copy the original structured data in two np array with all the trajectories\n",
    "                    dataset[ts_idx,:,:] = data.processed[user][video][:,1:] ## SKIP FIRST COLUMN\n",
    "\n",
    "                    # Time-series Index, combining the structure per user, per video.\n",
    "                    ts_idx += 1\n",
    "\n",
    "            ## SAVE FILES\n",
    "            # Create dataframe with time index\n",
    "            labels = pd.DataFrame(data=labels, columns=labels_cols)\n",
    "            labels.to_csv(input_files[0], index=False)\n",
    "            print(\"Cluster index created at\", input_files[0])\n",
    "\n",
    "            # Save timestamps\n",
    "            np.savetxt(input_files[1], timestamps, fmt='%f') # Supress scientific notation\n",
    "            print(\"Timestamps created at\",input_files[1])\n",
    "\n",
    "            # Create pickle file with combined time-series for clustering\n",
    "            utils.save_binaryfile_npy(dataset, input_files[2])\n",
    "            print(\"Head movement resampled created at\", input_files[2])\n",
    "\n",
    "\n",
    "            ### ---- CONTROL RETRIES\n",
    "            if tries+1 < RELOAD_TRIES:\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Finish iteration\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">> FINISHED WITHOUT ERRORS!!\n"
     ]
    }
   ],
   "source": [
    "print(\">> FINISHED WITHOUT ERRORS!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd004635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94",
   "display_name": "Python 3.7.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}