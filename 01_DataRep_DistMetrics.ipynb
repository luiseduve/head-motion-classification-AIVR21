{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tasks with Kinematic Time Series from Head Pose Estimation from HMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "- IMT: Preprocessed structured dataset from paper [here](http://doi.org/10.1145/3083187.3083215)\n",
    "- Tsinghua: Preprocessed structured dataset from paper [here](https://wuchlei-thu.github.io/)\n",
    "\n",
    "## 2. Data Representations\n",
    "- Quaternion (4D)\n",
    "- Euler Rotation (3D)\n",
    "- Yaw Rotation (1D)\n",
    "\n",
    "## 3. Feature Extraction 1/2\n",
    "- Raw time-series\n",
    "- Velocity\n",
    "- Acceleration\n",
    "\n",
    "## 4. Feature Extraction 2/2\n",
    "- Summary statistics\n",
    "    - Maximum\n",
    "    - Minimum\n",
    "    - Average\n",
    "    - Standard deviation\n",
    "    - Median\n",
    "\n",
    "## 5. Classifier\n",
    "- Feature-based classifiers\n",
    "    - 1-NN + DTW\n",
    "- Time-series classifiers (their input is directly the time series from **Data representations**)\n",
    "    - STSF\n",
    "    - ROCKET\n",
    "\n",
    "## Evaluation\n",
    "- Each classifier is evaluated by comparing the accuracy over Monte Carlo simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add files to sys.path\n",
    "from pathlib import Path\n",
    "import sys,os\n",
    "this_path = None\n",
    "try:\n",
    "    this_path = str(os.path.dirname(os.path.abspath(__file__))) #str(Path().absolute())+\"/\" # str(os.path.dirname(__file__))\n",
    "except:\n",
    "    this_path = str(Path().absolute())+\"/\" #str(Path().absolute())+\"/\" # str(os.path.dirname(__file__))\n",
    "print(\"File Path:\", this_path)\n",
    "sys.path.append(os.path.join(this_path, \"kinemats\"))\n",
    "\n",
    "# Import classes\n",
    "import utils  # Utils for generation of files and paths\n",
    "import quaternion_math\n",
    "\n",
    "from plotter.ts_visualization import *\n",
    "import ts_processing\n",
    "import ts_classification\n",
    "\n",
    "# Import data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.rcParams['text.usetex'] = True\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "import experiment_config\n",
    "from experiment_config import Datasets, DataRepresentation, Classifiers\n",
    "from ts_classification import EnumDistMetrics\n",
    "\n",
    "# All the files generated from this notebook are in a subfolder with this name\n",
    "NOTEBOOK_SUBFOLDER_NAME = '1_DataRep_DistMetrics/'\n",
    "\n",
    "# Filenames of created files from this script\n",
    "FILENAME_DATASET_QUATERNION = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Quaternion))      # generates \"dataset_quaternion\"\n",
    "FILENAME_DATASET_EULER = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Euler))\n",
    "# FILENAME_DATASET_SPHERICAL = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Spherical))\n",
    "FILENAME_DATASET_YAW = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Yaw))\n",
    "\n",
    "#### NOTE: This dictionary is reassigned later in the code whenever the datasets are generated.\n",
    "DICT_DATA_REPRESENTATIONS = {\n",
    "    DataRepresentation.Quaternion:  None,\n",
    "    DataRepresentation.Euler:       None,\n",
    "    # DataRepresentation.Spherical:   None,\n",
    "    DataRepresentation.Yaw:         None,\n",
    "}\n",
    "\n",
    "# Dictionary to convert a datarepresentation into a num - To be stored in the numpy array for results\n",
    "DICT_DATAREP_TO_NUM = { k:i for i,k in enumerate(DICT_DATA_REPRESENTATIONS.keys())}\n",
    "\n",
    "# Distance metrics that are applied to do cross-similarity matrices for each dataset\n",
    "DICT_DIST_METRICS = {\n",
    "    # Without clamping distance values\n",
    "    # \"euclidean\":        EnumDistMetrics.Euclidean,                 # Standard Euclidean L2-norm\n",
    "    # Specific Clamped Euclidean (Different for euler and quaternions) # First has to be for quaternions\n",
    "    # \"euclid_specif\":    [EnumDistMetrics.EuclideanClamped_Quat, EnumDistMetrics.EuclideanClamped_EulerAngle], \n",
    "    # DTW per dimension, then adds them together\n",
    "    \"dtw\":              EnumDistMetrics.DtwSumMultiDim\n",
    "}\n",
    "# Dictionary to convert a distance metric into a num - To be stored in the numpy array for results\n",
    "DICT_DISTMETRIC_TO_NUM = { k:i for i,k in enumerate(DICT_DIST_METRICS.keys())}\n",
    "\n",
    "# Classification methods to apply\n",
    "LIST_CLASSIFIERS = [Classifiers.KNN_1]\n",
    "# if experiment_config.DATASET_MAIN == Datasets.IMT:\n",
    "    # LIST_CLASSIFIERS.append(Classifiers.KNN_7)\n",
    "# elif experiment_config.DATASET_MAIN == Datasets.Tsinghua:\n",
    "    # LIST_CLASSIFIERS.append(Classifiers.KNN_11)\n",
    "\n",
    "# How many iterations to conduct the steps: [training-testing-classification]\n",
    "MC_ITERATIONS = experiment_config.MC_ITERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINATIONS FOR CROSS-SIMILARITY MATRICES\n",
    "# Every data representation is going to be assessed with each type of metric\n",
    "# for the case where the metric is a list, it specifies whether it is for quaternion or other data rep.\n",
    "combinations_to_analyze = []\n",
    "for dr, datarep in enumerate(DICT_DATA_REPRESENTATIONS.keys()):\n",
    "    for m,metric in enumerate(DICT_DIST_METRICS.keys()):\n",
    "        comb = (datarep,metric) \n",
    "        combinations_to_analyze.append( comb )\n",
    "        print(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# UTILITY FUNCTIONS\n",
    "\n",
    "Generate paths to write output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_DATASET = str(experiment_config.DATASET_MAIN)+\"/\"\n",
    "print(STR_DATASET)\n",
    "def gen_path_plot(filename):\n",
    "    # Generates full paths for PLOTS just by specifying a name\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.PLOT_FOLDER, \\\n",
    "                                        subfolders=STR_DATASET+NOTEBOOK_SUBFOLDER_NAME, \\\n",
    "                                        file_extension=experiment_config.IMG_FORMAT, save_files=experiment_config.EXPORT_PLOTS)\n",
    "\n",
    "def gen_path_temp(filename, subfolders=\"\", extension=experiment_config.TEMP_FORMAT):\n",
    "    # Generates full paths for TEMP FILES just by specifying a name\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.TEMP_FOLDER, \\\n",
    "                                        subfolders=STR_DATASET+subfolders, \\\n",
    "                                        file_extension=extension)\n",
    "\n",
    "def gen_path_results(filename, subfolders=\"\", extension=\"\"):\n",
    "    # Generates full paths for RESULTS FILES (like pandas dataframes)\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.RESULTS_FOLDER, \\\n",
    "                                        subfolders=STR_DATASET+NOTEBOOK_SUBFOLDER_NAME+subfolders, \\\n",
    "                                        file_extension=extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASETS: Load and preprocess\n",
    "\n",
    "Datasets are adapted to have the reference right-hand coordinate system used: front=1, left=j, up=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>>>LOADING DATASETS\")\n",
    "dataset = None\n",
    "classes = None\n",
    "\n",
    "# Coordinate reference system. All datasets should be transformed to match this coordinate system.\n",
    "AXIS_FRONT=1\n",
    "AXIS_LEFT=2\n",
    "AXIS_UP=3\n",
    "\n",
    "# Quaternion representation. All datasets should be transformed to match this quaternion representation.\n",
    "# [qw, qi, qj qk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset IMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.IMT:\n",
    "    \n",
    "    # Data for combined time series to cluster\n",
    "    labels_filename = experiment_config.DATASET_LABELS # Cluster index TRUE_LABEL\n",
    "    timestamps_filename = experiment_config.DATASET_TIMESTAMPS # Timestamps\n",
    "    dataset_filename = experiment_config.DATASET_DATA # Resampled data stats\n",
    "\n",
    "    labels = pd.read_csv(labels_filename)\n",
    "    timestamps = np.loadtxt(timestamps_filename)\n",
    "    dataset = utils.load_binaryfile_npy(dataset_filename)\n",
    "\n",
    "    dataset = np.clip(dataset, -1, 1)\n",
    "\n",
    "    ## QUATERNION REPRESENTATION\n",
    "    # originally [qw, qi, qj, qk]\n",
    "\n",
    "    ## COORDINATE SYSTEM: ORIGINAL ACCORDING TO PAPER: i>Front, j>Left, k>Up\n",
    "    # In original coordinate system.\n",
    "\n",
    "    #labels, timestamps, dataset = data_loader.dataset_IMT.load_dataset_IMT(labels_filename, timestamps_filename, dataset_filename)\n",
    "\n",
    "    # Classes are the labels of the videos \n",
    "    classes = labels[\"videoId\"].to_numpy(dtype=np.int32)\n",
    "    ## Classes are the user watching the videos\n",
    "    #classes = labels[\"user\"].to_numpy(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset Tsinghua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_config.DATASET_MAIN == Datasets.Tsinghua:\n",
    "        \n",
    "    # Data for combined time series to cluster\n",
    "    labels_filename = experiment_config.DATASET_LABELS # Cluster index TRUE_LABEL\n",
    "    timestamps_filename = experiment_config.DATASET_TIMESTAMPS # Timestamps\n",
    "    dataset_filename = experiment_config.DATASET_DATA # Resampled data stats\n",
    "\n",
    "    labels = pd.read_csv(labels_filename)\n",
    "    timestamps = np.loadtxt(timestamps_filename)\n",
    "    dataset = utils.load_binaryfile_npy(dataset_filename)\n",
    "\n",
    "    dataset = np.clip(dataset, -1, 1)\n",
    "\n",
    "    ## QUATERNION REPRESENTATION\n",
    "    # originally [qi, qj, qk, qw] --> Change to [qw,qi,qj,qk]\n",
    "    dataset_copy = dataset.copy()\n",
    "    dataset[...,0] = dataset_copy[...,3]\n",
    "    dataset[...,1] = dataset_copy[...,0]\n",
    "    dataset[...,2] = dataset_copy[...,1]\n",
    "    dataset[...,3] = dataset_copy[...,2]\n",
    "\n",
    "    ## COORDINATE SYSTEM: Unity is left-handed (right, up, front), needs to be converted to right-handed (front, left, up)\n",
    "    dataset_copy = dataset.copy()\n",
    "    dataset[...,1] = dataset_copy[...,3]     # Change FRONT to first position\n",
    "    dataset[...,2] = -1*dataset_copy[...,1]  # Change RIGHT to second position with opposite orientation in the coordinate system to make it LEFT\n",
    "    dataset[...,3] = dataset_copy[...,2]     # Change UP from second to third position\n",
    "\n",
    "    #labels, timestamps, dataset = data_loader.dataset_IMT.load_dataset_IMT(labels_filename, timestamps_filename, dataset_filename)\n",
    "\n",
    "    # Classes are the labels of the videos \n",
    "    classes = labels[\"videoId\"].to_numpy(dtype=np.int32)\n",
    "    ## Classes are the user watching the videos\n",
    "    #classes = labels[\"user\"].to_numpy(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access the dataset\n",
    "\n",
    "- `timestamps` is a ndarray that contains the value of the time axis of the time series (in seconds).\n",
    "- `classes` is a numpy array that contains the labels of the 290 time series.\n",
    "- `dataset` is a ndarray of  3 dimensions as follows: `[`time series index (mapped to labels `id`), time series values, quaterion values (q0, qi, qj, qk)`]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.unique(classes).size\n",
    "\n",
    "if(dataset.ndim == 2):\n",
    "    dataset = np.expand_dims(dataset, axis=2)\n",
    "\n",
    "num_ts = dataset.shape[0]\n",
    "length_ts = dataset.shape[1]\n",
    "num_dims = dataset.shape[2]\n",
    "\n",
    "print(\"Timestamps:\", type(timestamps), timestamps.shape)\n",
    "print(\"Dataset\", type(dataset), dataset.shape)\n",
    "print(\"Classes\", type(classes), classes.shape)\n",
    "print(f\"num_classes={num_classes}\")\n",
    "print(f\"num_ts={num_ts}\")\n",
    "print(f\"length_ts={length_ts}\")\n",
    "print(f\"num_dims={num_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(experiment_config.SHOW_PLOTS): plot_histogram_class_balance([pd.Series(classes)], plot_titles = [\"Dataset\"], figsize=(5,4), save_path=gen_path_plot(\"class_balance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2% rolling window\n",
    "ROLLING_WINDOW_PLOT = int(length_ts*0.02) \n",
    "print(f\"ROLLING_WINDOW_PLOT={ROLLING_WINDOW_PLOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation (Time-Series Representation)\n",
    "\n",
    "One of the main problems with the use of rotations in ML is that they are discontinuous in the Euclidean space of four or fewer dimensions. But they have continuous representations in 5D and 6D (Exponential Maps). Reference: https://arxiv.org/abs/1812.07035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quaternion\n",
    "In the dataset, the head movemente are stored as quaternions following the structure: **(timestamp, q0, qi, qj, qk)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>>>LOADING/CREATING QUATERNION DATA\")\n",
    "# Data for combined time series to cluster\n",
    "dataset_quaternion_filename = gen_path_temp( FILENAME_DATASET_QUATERNION ) # Quaternion dataset\n",
    "\n",
    "# Load or create dataframe with statistics of initial dataset (58 users, 5 videos)\n",
    "dataset_quaternion = None\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [dataset_quaternion_filename]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(experiment_config.RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{experiment_config.RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        dataset_quaternion = utils.load_binaryfile_npy(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "        dataset_quaternion = dataset.copy() # Original dataset is quaternion, just copy it!\n",
    "        utils.save_binaryfile_npy(dataset_quaternion, input_files[0])\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < experiment_config.RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Finish iteration\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the average magnitude of the quaternions.\n",
    "magnitudes = [np.linalg.norm(dataset_quaternion[traj,values,:]) for traj in range(num_ts) for values in range(length_ts) ]\n",
    "print(\"\\MaxMin Magnitudes of Quaternions in dataset\",np.max(magnitudes),np.min(magnitudes))\n",
    "# CONCLUSION: ALL QUATERNION ARE VALID SINCE THEY ARE UNIT QUATERNIONS (Error: 4e-7)\n",
    "\n",
    "# Rotate a 3D vector according to quaternion\n",
    "print(\"\\nExample of rotation over a vector:\")\n",
    "print(quaternion_math.point_rotation_by_quaternion([1, 0, 0],[0.7071203316249954, 0.0, 0.7071203316249954, 0.0]))\n",
    "# This quaternion corresponds to a rotation 90-degrees counterclockwise around Y-axis\n",
    "\n",
    "dataset_quaternion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(experiment_config.SHOW_PLOTS): plot_mean_std_ts(dataset_quaternion, classes, \\\n",
    "                    rolling_window_size=ROLLING_WINDOW_PLOT, \\\n",
    "                    axes_labels=[\"qw\",\"qi\",\"qj\",\"qk\"], \\\n",
    "                    colors=['k','r','g','b'], \\\n",
    "                    figsize=(4,2), \\\n",
    "                    save_path=gen_path_plot(\"quaternion_summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Euler Angles\n",
    "\n",
    "### Converting from Quaternion to Euler Angles (Tait-Bryan Representation)\n",
    "\n",
    "$ \\text{roll}, \\quad \\phi = \\operatorname{atan2} \\left(2\\left(q_r q_i + q_j q_k\\right),1 - 2\\left(q_i^2 + q_j^2\\right)\\right) $\n",
    "\n",
    "$ \\text{pitch}, \\quad \\theta = \\arcsin \\left(2\\left(q_r q_j - q_k q_i\\right)\\right)$\n",
    "\n",
    "$ \\text{yaw}, \\quad \\psi = \\operatorname{atan2} \\left(2\\left(q_r q_k + q_i q_j\\right),1 - 2\\left(q_j^2 + q_k^2\\right)\\right)$\n",
    "\n",
    "There are some singularities when $pitch \\approx \\pm \\pi/2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>>>LOADING/CREATING EULER DATA\")\n",
    "# Data for combined time series to cluster\n",
    "dataset_euler_filename = gen_path_temp( FILENAME_DATASET_EULER ) # Resampled data stats\n",
    "\n",
    "# Load or create dataframe with statistics of initial dataset (58 users, 5 videos)\n",
    "dataset_euler = None\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [dataset_euler_filename]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(experiment_config.RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{experiment_config.RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        dataset_euler = utils.load_binaryfile_npy(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "        # Axis direction w.r.t Unity coordinate system\n",
    "        dataset_euler = quaternion_math.quaternion_to_euler(dataset_quaternion, axis_qw=0, axis_front=AXIS_FRONT, axis_left=AXIS_LEFT, axis_up=AXIS_UP)        \n",
    "        utils.save_binaryfile_npy(dataset_euler, input_files[0])\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < experiment_config.RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Finish iteration\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_euler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(experiment_config.SHOW_PLOTS): plot_mean_std_ts(dataset_euler, classes, \\\n",
    "                    rolling_window_size=ROLLING_WINDOW_PLOT, \\\n",
    "                    axes_labels=[\"Yaw $\\psi$\",\"Pitch $\\\\theta$\",\"Roll $\\phi$\"], \\\n",
    "                    colors=['r','g','b'], \\\n",
    "                    figsize=(4,2), \\\n",
    "                    save_path=gen_path_plot(\"euler_summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spherical\n",
    "\n",
    "### Converting from Quaternion to center of viewport in XY-plane\n",
    "\n",
    "According to the reference frame in the dataset, the coordinate $\\hat{i}$ represents the front of the user. Here, we extract the center of the viewport in relation to the orthogonal projection of the 360 video (i.e. unwrapping the sphere into the 2D plane)\n",
    "\n",
    "Find the resulting vector from the **quaternion rotation operator** of a vector $\\mathbf{v}=[1,0,0]$ such as described in the *Section 5.15.1 of the book 1999, Kuipers, Quaternions and Rotation Sequences.*, as: \n",
    "\n",
    "$L_q(\\mathbf{v})=q\\mathbf{v}q*$  Where $\\mathbf{v}$ is a vector in $\\mathbb{R}^3$ expanded as $\\mathbf{v} = (0, v_x, v_y, v_z)$ for the calculation of the quaternion sequence.\n",
    "\n",
    "After finding the sequence of vectors $ P = [x,y,z] \\in \\mathbb{R}^3$ that define the trajectory of the viewport. It is converted to spherical coordinates as $\\rho$: radial distance, $\\theta$: azimuthal angle, $\\phi$: polar angle:\n",
    "\n",
    "$\\rho = \\sqrt{x^2 + y^2 + z^2}, \\quad \\rho \\in \\mathbb{R}^+$, in this case $\\rho = 1$ because $v$ is a unit vector and quaternion rotations are around the **unitary** great circle.\n",
    "\n",
    "$\\theta = \\arctan{\\frac{y}{x}}, \\quad \\theta \\in (-\\pi,\\pi]$, positive angles indicate rotation CCW (i.e. turning the head to the left) from the center position.\n",
    "\n",
    "$\\phi = \\arccos{\\frac{z}{\\rho}}, \\quad \\phi \\in [0,\\pi]$, positive values indicate moving the head down, when user looks exactly forward, the value is $\\phi = \\pi/2$\n",
    "\n",
    "![spherical-coordinates](https://mathinsight.org/media/image/image/spherical_coordinates.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\t>>>LOADING/CREATING SPHERICAL DATA\")\n",
    "# ## CREATE FILE PICKLE\n",
    "# # Data for combined time series to cluster\n",
    "# dataset_spherical_filename = gen_path_temp( FILENAME_DATASET_SPHERICAL ) # Spherical dataset\n",
    "\n",
    "# # Load or create dataframe with statistics of initial dataset (58 users, 5 videos)\n",
    "# dataset_spherical = None\n",
    "\n",
    "# ### INPUTS / OUTPUTS\n",
    "# \"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "# input_files = [dataset_spherical_filename]\n",
    "\n",
    "# # Try to load files maximum two times\n",
    "# for tries in range(experiment_config.RELOAD_TRIES):\n",
    "#     try:\n",
    "#         ### LOAD FILE\n",
    "#         print(f\"Trying {tries+1}/{experiment_config.RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "#         ### CUSTOM SECTION TO READ FILES\n",
    "#         \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "#         dataset_spherical = utils.load_binaryfile_npy(input_files[0])\n",
    "#         print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         ### CREATE FILE\n",
    "#         print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "#         ### CUSTOM SECTION TO CREATE FILES \n",
    "#         \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "#         # The center of the viewport is the vector `viewport_perp`. Where it lands according to \n",
    "#         # rotations at each timepoint is found by `apply_quaternion_sequence`.\n",
    "#         viewport_perp = np.array([0,1,0,0]) # Vector front of user is Z (According to Unity reference system)\n",
    "\n",
    "#         center_viewport = quaternion_math.apply_quaternion_sequence(viewport_perp, dataset_quaternion)\n",
    "\n",
    "#         # All the first dimension of the quaternion should be zero. Because the reference vector lives in 3D\n",
    "#         if(center_viewport.shape[center_viewport.ndim-1]==4):\n",
    "#             print(\"Sum first dimension:\", center_viewport[...,0].sum())\n",
    "#             # Therefore it can be deleted\n",
    "#             center_viewport = center_viewport[...,1:].copy()\n",
    "        \n",
    "#         ## Clip the values: Trigonometric functions might generate errors. E.g. arccos not defined for -1.0000001, clip to -1\n",
    "#         center_viewport = np.clip(center_viewport, -1, 1)\n",
    "\n",
    "#         # Quaternions are still unitary vectors\n",
    "#         mags = np.apply_along_axis(np.linalg.norm, center_viewport.ndim-1, center_viewport)\n",
    "#         print(\"Positions of quaternions that are not magnitude 1: (Should be empty)\")\n",
    "#         print( np.where(np.abs(mags - 1) > 0.0001) ) # This result should be empty, because all quaternions should be unit-quat\n",
    "\n",
    "#         rho = np.ones(center_viewport[...,0].shape)         ## Magnitude 1 for all quaternions\n",
    "#         theta = np.arctan2(center_viewport[...,1],center_viewport[...,0])\n",
    "#         phi = np.arccos(center_viewport[...,2]/rho)        \n",
    "        \n",
    "#         print(f\"Rho range = \\t{[np.min(rho),np.max(rho)]}, (should be [1,1]), shape={phi.shape}\")\n",
    "#         print(f\"Theta range = \\t{[np.min(theta),np.max(theta)]}, (should be [-pi,pi]) shape={theta.shape}\")\n",
    "#         print(f\"Phi range = \\t{[np.min(phi),np.max(phi)]}, (should be [0,pi]) shape={phi.shape}\")\n",
    "\n",
    "#         # Join both angles in a single array\n",
    "#         dataset_spherical = np.stack([theta, phi], -1)\n",
    "\n",
    "#         utils.save_binaryfile_npy(dataset_spherical, input_files[0])\n",
    "\n",
    "#         ### ---- CONTROL RETRIES\n",
    "#         if tries+1 < experiment_config.RELOAD_TRIES:\n",
    "#             continue\n",
    "#         else:\n",
    "#             raise\n",
    "    \n",
    "#     # Finish iteration\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_spherical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(experiment_config.SHOW_PLOTS): plot_mean_std_ts(dataset_spherical, classes, \\\n",
    "#                     rolling_window_size=ROLLING_WINDOW_PLOT, \\\n",
    "#                     axes_labels=[\"Azimuth $\\\\theta$\",\"Polar angle $\\phi$\"], \\\n",
    "#                     colors=['r','g'], \\\n",
    "#                     figsize=(4,2), \\\n",
    "#                     save_path=gen_path_plot(\"spherical_summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Yaw rotation around z-axis\n",
    "\n",
    "Value in Euler angle of Yaw($\\psi$) is the same than azimuth($\\theta$) from spherical representation, which range is $(-\\pi,\\pi]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t>>>LOADING/CREATING YAW DATA\")\n",
    "# Data for combined time series to cluster\n",
    "dataset_yaw_filename = gen_path_temp( FILENAME_DATASET_YAW ) # Yaw angles dataset\n",
    "\n",
    "# Load or create dataframe with statistics of initial dataset (58 users, 5 videos)\n",
    "dataset_yaw = None\n",
    "\n",
    "### INPUTS / OUTPUTS\n",
    "\"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "input_files = [dataset_yaw_filename]\n",
    "\n",
    "# Try to load files maximum two times\n",
    "for tries in range(experiment_config.RELOAD_TRIES):\n",
    "    try:\n",
    "        ### LOAD FILE\n",
    "        print(f\"Trying {tries+1}/{experiment_config.RELOAD_TRIES} to load files: {input_files}\")\n",
    "        \n",
    "        ### CUSTOM SECTION TO READ FILES\n",
    "        \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "        dataset_yaw = utils.load_binaryfile_npy(input_files[0])\n",
    "        print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "    except Exception as e:\n",
    "        ### CREATE FILE\n",
    "        print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "        ### CUSTOM SECTION TO CREATE FILES \n",
    "        \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "        \n",
    "        dataset_yaw = dataset_euler[...,0] # Yaw is one dimension of the spherical coordinates\n",
    "\n",
    "        # Keep being a 3D numpy array, despite it only has 2. For compatibility with the rest of the functions\n",
    "        dataset_yaw = np.expand_dims(dataset_yaw, axis=2)\n",
    "\n",
    "        utils.save_binaryfile_npy(dataset_yaw, input_files[0])\n",
    "\n",
    "        ### ---- CONTROL RETRIES\n",
    "        if tries+1 < experiment_config.RELOAD_TRIES:\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Finish iteration\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Yaw range = \\t{[np.min(dataset_yaw),np.max(dataset_yaw)]}, (should be [-pi,pi]) shape={dataset_yaw.shape}\")\n",
    "\n",
    "dataset_yaw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(experiment_config.SHOW_PLOTS): plot_mean_std_ts(dataset_yaw, classes, \\\n",
    "                    rolling_window_size=ROLLING_WINDOW_PLOT, \\\n",
    "                    axes_labels=[\"Yaw (Radians)\"], \\\n",
    "                    colors=['r'], \\\n",
    "                    figsize=(4,2), \\\n",
    "                    save_path=gen_path_plot(\"yaw_summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Summary`\n",
    "\n",
    "Until this point, the head movements are stored as in these data representations: \n",
    "- Quaternion (`dataset_quaternion`)\n",
    "- Euler Angles (`dataset_euler`)\n",
    "- ~~Spherical Angles (`dataset_spherical`)~~\n",
    "- Rotation around Z-axis (`dataset_yaw`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NOTE:` REDEFINITION OF DATASETS\n",
    "The dictionary is redefined now, since the datasets were properly loaded/created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = num_classes # Global variable counting number of different classes in the dataset\n",
    "# REDEFINE DICT WITH CORRESPONDING DATASETS\n",
    "DICT_DATA_REPRESENTATIONS = {\n",
    "    DataRepresentation.Quaternion:  dataset_quaternion,\n",
    "    DataRepresentation.Euler:       dataset_euler,\n",
    "    # DataRepresentation.Spherical:   dataset_spherical,\n",
    "    DataRepresentation.Yaw:         dataset_yaw,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Distance Metrics: Euclidean, Specific Euclidean, and DTW\n",
    "\n",
    "** `NOTE >> ` Skip: This implementation was replaced by the optimized KNN from `sktime`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test files that will be generated from the combination analysis\n",
    "# Dictionary to know from where to load the CrossDistance matrix for a specific data representation, and specific distance metric\n",
    "DICT_CDIST_FILES = { str(k):{} for k in DICT_DATA_REPRESENTATIONS.keys() } # Copy the keys from datarepresentations\n",
    "for datarep,metric in combinations_to_analyze:\n",
    "    filepath = gen_path_temp(f\"{NOTEBOOK_SUBFOLDER_NAME}{experiment_config.PREFIX_CDIST_MATRIX}{str(datarep)}_{metric}\", extension=\".csv\" )\n",
    "    DICT_CDIST_FILES[str(datarep)][metric] = filepath # Add subkeys with metric, per each datarep\n",
    "    print(filepath)\n",
    "    \n",
    "# Save the index in a file.\n",
    "utils.create_json(DICT_CDIST_FILES, gen_path_temp(f\"{NOTEBOOK_SUBFOLDER_NAME}_index{experiment_config.PREFIX_CDIST_MATRIX}\", extension=\".json\" ))\n",
    "print(\"Example for Quaternion Data Representation:\")\n",
    "print(DICT_CDIST_FILES[str(DataRepresentation.Euler)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"\\t>>>LOADING/CREATING CROSS-SIMILARITY MATRICES\")\n",
    "\n",
    "# for datarep,metric in combinations_to_analyze:\n",
    "#     # Filename of the file containing demographics and HMD movements data\n",
    "#     crossdistance_matrix_filename = DICT_CDIST_FILES[str(datarep)][metric]\n",
    "\n",
    "#     ### INPUTS / OUTPUTS\n",
    "#     \"\"\"EDIT CUSTOM FILENAMES\"\"\"\n",
    "#     input_files = [crossdistance_matrix_filename]\n",
    "\n",
    "#     # Try to load files maximum two times\n",
    "#     RELOAD_TRIES = 3\n",
    "#     for tries in range(RELOAD_TRIES):\n",
    "#         try:\n",
    "#             ### LOAD FILE\n",
    "#             print(f\"Trying {tries+1}/{RELOAD_TRIES} to load files: {input_files}\")\n",
    "            \n",
    "#             ### CUSTOM SECTION TO READ FILES\n",
    "#             \"\"\"EDIT CUSTOM READ\"\"\"\n",
    "#             final_cdist_matrix = utils.load_numpy_2D(input_files[0])\n",
    "#             print(f\"File {input_files[0]} was successfully loaded\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             ### CREATE FILE\n",
    "#             print(f\"File not found. Creating again! {e}\")\n",
    "\n",
    "#             ### CUSTOM SECTION TO CREATE FILES \n",
    "#             \"\"\"EDIT CUSTOM WRITE\"\"\"\n",
    "\n",
    "#             final_cdist_matrix = np.random.rand(20,100)\n",
    "            \n",
    "#             datarep_dataset = DICT_DATA_REPRESENTATIONS[datarep]\n",
    "#             dist_metric = DICT_DIST_METRICS[metric]\n",
    "\n",
    "#             # For the case of specific distmetric, it varies for quaternion or euler angles\n",
    "#             ## NOTE: THIS IS FOR THE CASE WHERE THE SAME LOOP INVOLVES DIFF DIST METRICS FOR \n",
    "#             # QUATERNIONS AND EULER. HERE WE ASSUME THAT ALWAYS THE QUATERNION DIST METRIC\n",
    "#             # IS IN THE FIRST POSITION OF THE LIST, AND THE\n",
    "#             if (type(dist_metric) is list):\n",
    "#                 if datarep == DataRepresentation.Quaternion:\n",
    "#                     dist_metric = dist_metric[0]\n",
    "#                 else: # It is a euler representation\n",
    "#                     dist_metric = dist_metric[1]\n",
    "#                 #print(f\"CHOOSING DIST METRIC FOR {datarep} === {dist_metric}\") \n",
    "            \n",
    "#             # Calculate cross-distance matrix\n",
    "#             final_cdist_matrix = ts_classification.distance_time_series(datarep_dataset, axis=0, distance_metric=dist_metric)\n",
    "\n",
    "#             # Save files\n",
    "#             utils.save_numpy_2D(final_cdist_matrix, input_files[0])\n",
    "\n",
    "#             ### ---- CONTROL RETRIES\n",
    "#             if tries+1 < RELOAD_TRIES:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 raise\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> FINISHED WITHOUT ERRORS!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd0f3aec1f4fef7a88c2258d5b84a8b82909f076cff2bcb16988c856ebc42b66954",
   "display_name": "Python",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}