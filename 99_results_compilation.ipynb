{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tasks with Kinematic Time Series from Head Pose Estimation from HMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Results compilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add files to sys.path\n",
    "from pathlib import Path\n",
    "import sys,os\n",
    "this_path = None\n",
    "try:\n",
    "    this_path = str(os.path.dirname(os.path.abspath(__file__))) #str(Path().absolute())+\"/\" # str(os.path.dirname(__file__))\n",
    "except:\n",
    "    this_path = str(Path().absolute())+\"/\" #str(Path().absolute())+\"/\" # str(os.path.dirname(__file__))\n",
    "print(\"File Path:\", this_path)\n",
    "sys.path.append(os.path.join(this_path, \"kinemats\"))\n",
    "\n",
    "\n",
    "# Import classes\n",
    "import utils  # Utils for generation of files and paths\n",
    "\n",
    "from plotter.ts_visualization import *\n",
    "import ts_processing\n",
    "import ts_classification\n",
    "\n",
    "# Import data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = False\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from libs.criticaldifference import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "import experiment_config\n",
    "from experiment_config import Datasets, DataRepresentation, Classifiers\n",
    "from ts_classification import EnumDistMetrics\n",
    "\n",
    "### SPECIFIC CONSTANTS\n",
    "\n",
    "# if(experiment_config.DATASET_MAIN is not Datasets.Tsinghua):\n",
    "#     raise ValueError(\"Set experiment_config.DATASET_MAIN to Tsinghua, because dataset 3D plots are based on it.\")\n",
    "\n",
    "# Filenames of created files from this script\n",
    "FILENAME_DATASET_QUATERNION = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Quaternion))      # generates \"dataset_quaternion\"\n",
    "FILENAME_DATASET_EULER = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Euler))\n",
    "FILENAME_DATASET_SPHERICAL = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Spherical))\n",
    "FILENAME_DATASET_YAW = str(experiment_config.PREFIX_DATASET+str(DataRepresentation.Yaw))\n",
    "\n",
    "# All the files generated from this notebook are in a subfolder with this name\n",
    "NOTEBOOK_SUBFOLDER_NAME = '99_Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# UTILITY FUNCTIONS\n",
    "\n",
    "Generate paths to write output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_DATASET = str(experiment_config.DATASET_MAIN)+\"/\"\n",
    "print(STR_DATASET)\n",
    "def gen_path_plot(filename, extension=None):\n",
    "    # Generates full paths for PLOTS just by specifying a name\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.PLOT_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_SUBFOLDER_NAME, \\\n",
    "                                        file_extension=experiment_config.IMG_FORMAT if None else extension, save_files=experiment_config.EXPORT_PLOTS)\n",
    "\n",
    "def gen_path_temp(filename, subfolders=\"\", extension=experiment_config.TEMP_FORMAT):\n",
    "    # Generates full paths for TEMP FILES just by specifying a name\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.TEMP_FOLDER, \\\n",
    "                                        subfolders=STR_DATASET+subfolders, \\\n",
    "                                        file_extension=extension)\n",
    "\n",
    "def gen_path_results(filename, subfolders=\"\", extension=\"\"):\n",
    "    # Generates full paths for RESULTS FILES (like pandas dataframes)\n",
    "    return utils.generate_complete_path(filename, \\\n",
    "                                        main_folder=experiment_config.RESULTS_FOLDER, \\\n",
    "                                        subfolders=NOTEBOOK_SUBFOLDER_NAME+subfolders, \\\n",
    "                                        file_extension=extension)"
   ]
  },
  {
   "source": [
    "---\n",
    "# RESULTS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD RESULTS FROM CUSTOM FOLDER CONTAINING RESULTS FROM VIDEO CLASSIFICATION\n",
    "TEMP_RESULTS_FOLDER = experiment_config.ROOT+\"results_classesAsVideos/\"\n",
    "\n",
    "# IMT dataset\n",
    "imt_fbc = pd.read_csv(TEMP_RESULTS_FOLDER + \"IMT/2_FeatureBasedClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "imt_fbc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "imt_fbc[\"classifier\"] = imt_fbc[\"classifier\"].map({\"Classifiers.KNN\":\"KNN\", \"Classifiers.DT\":\"DT\", \"Classifiers.RF\":\"RF\", \"Classifiers.GBM\":\"GBM\"})\n",
    "imt_fbc[\"datatype\"] = imt_fbc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "imt_fbc[\"methodtype\"] = \"fbc\"\n",
    "\n",
    "imt_tsc = pd.read_csv(TEMP_RESULTS_FOLDER + \"IMT/3_TimeSeriesClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "imt_tsc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "imt_tsc[\"classifier\"] = imt_tsc[\"classifier\"].map({\"Classifiers.KNN\":\"1NN-DTW\", \"Classifiers.ROCKET\":\"ROCKET\", \"Classifiers.MiniRocket\":\"MiniRocket\"})\n",
    "# imt_tsc[\"classifier\"] = imt_tsc[\"classifier\"].replace(\"Classifiers.KNN\", \"Classifiers.KNNts\")\n",
    "imt_tsc[\"datatype\"] = imt_tsc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "imt_tsc[\"methodtype\"] = \"tsc\"\n",
    "\n",
    "IMT_results1 = pd.concat([imt_fbc, imt_tsc], ignore_index=True)\n",
    "IMT_results1[\"dataset\"] = \"IMT\"\n",
    "\n",
    "# Tsinghua dataset\n",
    "tsg_fbc = pd.read_csv(TEMP_RESULTS_FOLDER + \"Tsinghua/2_FeatureBasedClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "tsg_fbc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "tsg_fbc[\"classifier\"] = tsg_fbc[\"classifier\"].map({\"Classifiers.KNN\":\"KNN\", \"Classifiers.DT\":\"DT\", \"Classifiers.RF\":\"RF\", \"Classifiers.GBM\":\"GBM\"})\n",
    "tsg_fbc[\"datatype\"] = tsg_fbc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "tsg_fbc[\"methodtype\"] = \"fbc\"\n",
    "\n",
    "tsg_tsc = pd.read_csv(TEMP_RESULTS_FOLDER + \"Tsinghua/3_TimeSeriesClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "tsg_tsc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "tsg_tsc[\"classifier\"] = tsg_tsc[\"classifier\"].map({\"Classifiers.KNN\":\"1NN-DTW\", \"Classifiers.ROCKET\":\"ROCKET\", \"Classifiers.MiniRocket\":\"MiniRocket\"})\n",
    "# imt_tsc[\"classifier\"] = imt_tsc[\"classifier\"].replace(\"Classifiers.KNN\", \"Classifiers.KNNts\")\n",
    "tsg_tsc[\"datatype\"] = tsg_tsc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "tsg_tsc[\"methodtype\"] = \"tsc\"\n",
    "\n",
    "TSINGHUA_results1 = pd.concat([tsg_fbc, tsg_tsc], ignore_index=True)\n",
    "TSINGHUA_results1[\"dataset\"] = \"Tsinghua\"\n",
    "\n",
    "# Compile results\n",
    "results1 = pd.concat([IMT_results1.copy(), TSINGHUA_results1.copy()], ignore_index=True)\n",
    "results1[\"classlabels\"] = \"videos\"\n",
    "\n",
    "### LOAD RESULTS FROM CUSTOM FOLDER CONTAINING RESULTS FROM USER IDENTIFICATION\n",
    "TEMP_RESULTS_FOLDER = experiment_config.ROOT+\"results_classesAsUsers/\"\n",
    "\n",
    "# IMT dataset\n",
    "imt_fbc = pd.read_csv(TEMP_RESULTS_FOLDER + \"IMT/2_FeatureBasedClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "imt_fbc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "imt_fbc[\"classifier\"] = imt_fbc[\"classifier\"].map({\"Classifiers.KNN\":\"KNN\", \"Classifiers.DT\":\"DT\", \"Classifiers.RF\":\"RF\", \"Classifiers.GBM\":\"GBM\"})\n",
    "imt_fbc[\"datatype\"] = imt_fbc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "imt_fbc[\"methodtype\"] = \"fbc\"\n",
    "\n",
    "imt_tsc = pd.read_csv(TEMP_RESULTS_FOLDER + \"IMT/3_TimeSeriesClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "imt_tsc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "imt_tsc[\"classifier\"] = imt_tsc[\"classifier\"].map({\"Classifiers.KNN\":\"1NN-DTW\", \"Classifiers.ROCKET\":\"ROCKET\", \"Classifiers.MiniRocket\":\"MiniRocket\"})\n",
    "# imt_tsc[\"classifier\"] = imt_tsc[\"classifier\"].replace(\"Classifiers.KNN\", \"Classifiers.KNNts\")\n",
    "imt_tsc[\"datatype\"] = imt_tsc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "imt_tsc[\"methodtype\"] = \"tsc\"\n",
    "\n",
    "IMT_results2 = pd.concat([imt_fbc, imt_tsc], ignore_index=True)\n",
    "IMT_results2[\"dataset\"] = \"IMT\"\n",
    "\n",
    "# Tsinghua dataset\n",
    "tsg_fbc = pd.read_csv(TEMP_RESULTS_FOLDER + \"Tsinghua/2_FeatureBasedClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "tsg_fbc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "tsg_fbc[\"classifier\"] = tsg_fbc[\"classifier\"].map({\"Classifiers.KNN\":\"KNN\", \"Classifiers.DT\":\"DT\", \"Classifiers.RF\":\"RF\", \"Classifiers.GBM\":\"GBM\"})\n",
    "tsg_fbc[\"datatype\"] = tsg_fbc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "tsg_fbc[\"methodtype\"] = \"fbc\"\n",
    "\n",
    "tsg_tsc = pd.read_csv(TEMP_RESULTS_FOLDER + \"Tsinghua/3_TimeSeriesClassifiers/\" + experiment_config.RESULTS_FILENAME + \".csv\")\n",
    "tsg_tsc.rename(columns = {\"dataset\":\"datatype\"}, inplace=True)\n",
    "tsg_tsc[\"classifier\"] = tsg_tsc[\"classifier\"].map({\"Classifiers.KNN\":\"1NN-DTW\", \"Classifiers.ROCKET\":\"ROCKET\", \"Classifiers.MiniRocket\":\"MiniRocket\"})\n",
    "# imt_tsc[\"classifier\"] = imt_tsc[\"classifier\"].replace(\"Classifiers.KNN\", \"Classifiers.KNNts\")\n",
    "tsg_tsc[\"datatype\"] = tsg_tsc[\"datatype\"].map({\"quaternion\":\"Quaternion\", \"euler\":\"Euler\", \"yaw\":\"Yaw\", \"all\":\"All\"})\n",
    "tsg_tsc[\"methodtype\"] = \"tsc\"\n",
    "\n",
    "TSINGHUA_results2 = pd.concat([tsg_fbc.copy(), tsg_tsc.copy()], ignore_index=True)\n",
    "TSINGHUA_results2[\"dataset\"] = \"Tsinghua\"\n",
    "\n",
    "# Compile results\n",
    "results2 = pd.concat([IMT_results2, TSINGHUA_results2], ignore_index=True)\n",
    "results2[\"classlabels\"] = \"users\"\n",
    "\n",
    "### FINAL COMPILATION OF RESULTS\n",
    "df_results = pd.concat([results1, results2], ignore_index=True)\n",
    "\n",
    "df_results.to_csv(gen_path_results(\"compilation_results_all\", extension=\".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results.shape)\n",
    "print(df_results.head())"
   ]
  },
  {
   "source": [
    "## Plot time series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD Tsinhua dataset and 3D plot qw,qk dimensions of quaternion\n",
    "\n",
    "labels_filename = experiment_config.DATASET_LABELS # Cluster index TRUE_LABEL\n",
    "timestamps_filename = experiment_config.DATASET_TIMESTAMPS # Timestamps\n",
    "labels = pd.read_csv(labels_filename)\n",
    "classes = labels[experiment_config.CLASS_COLUMN_NAME].to_numpy(dtype=np.int32)\n",
    "timestamps = np.loadtxt(timestamps_filename)\n",
    "\n",
    "# Datasets\n",
    "dataset_quaternion =  utils.load_binaryfile_npy( gen_path_temp( FILENAME_DATASET_QUATERNION ) )\n",
    "dataset_euler = utils.load_binaryfile_npy( gen_path_temp( FILENAME_DATASET_EULER ) )\n",
    "dataset_yaw = utils.load_binaryfile_npy( gen_path_temp( FILENAME_DATASET_YAW ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary_ts(data:np.ndarray, data_labels:np.ndarray, rolling_window_size = 5, axes_labels = [\"X\",\"Y\",\"Z\"], colors = ['r','g','b'], figsize=(10,20), save_path = None):\n",
    "    \"\"\"\n",
    "    Returns a plot with mean +- std of time series organized\n",
    "    in rows per class label, and columns per axis of movement.\n",
    "\n",
    "    :param data: Numpy array with first dimension equal to time series index, second dimension values, and third dimension axes.\n",
    "    :param data_labels: 1D numpy array with labels of each time series.\n",
    "    :return: Plot\n",
    "    :rtype: matplotlib fig\n",
    "    \"\"\"\n",
    "\n",
    "    # Force 3D array even if it is 2D array. For compatibility with functions\n",
    "    if(data.ndim == 2):\n",
    "        data = np.expand_dims(data, axis=2)\n",
    "\n",
    "    num_ts      = data.shape[0]\n",
    "    length_ts   = data.shape[1]\n",
    "    dim_ts      = data.shape[2]\n",
    "\n",
    "    classes = np.unique(data_labels)\n",
    "    num_classes = len(classes)\n",
    "    num_axes = len(axes_labels)\n",
    "\n",
    "    if dim_ts != num_axes or dim_ts != len(colors):\n",
    "        print(\"Please set `axes_labels` and `colors` with a list of same length than dimensions of one time series\")\n",
    "        return 1\n",
    "\n",
    "    cols_plot = num_axes\n",
    "    rows_plot = num_classes\n",
    "    fig, axes = plt.subplots(num_classes, num_axes, sharex=True, sharey=True, figsize=(figsize[0]*cols_plot, figsize[1]*rows_plot), gridspec_kw={\"wspace\":0.0,\"hspace\":0.0})\n",
    "    # from matplotlib import gridspec\n",
    "    # fig = plt.figure(figsize=(figsize[0]*cols_plot, figsize[1]*rows_plot))\n",
    "    # gs = gridspec.GridSpec(rows_plot, cols_plot, wspace=0.0, hspace=0.0)\n",
    "\n",
    "    for i in range(rows_plot):\n",
    "        for j in range(cols_plot):\n",
    "            t_class = classes[i]\n",
    "            t_axis = axes_labels[j]\n",
    "\n",
    "            # Filter the time series corresponding to each class\n",
    "            filtered_index = np.where(data_labels==t_class)[0].tolist()\n",
    "            data_temp = pd.DataFrame(data[filtered_index, :, j])\n",
    "\n",
    "            # Moving window with average to reduce noise.\n",
    "            # Calculates mean and std among all time series for the specific class\n",
    "            mean_ts = data_temp.rolling(rolling_window_size, axis=1).mean().mean()\n",
    "            sd_ts   = data_temp.rolling(rolling_window_size, axis=1).mean().std()\n",
    "\n",
    "            # Limits to fill are in the plot\n",
    "            low_line  = (mean_ts - sd_ts)\n",
    "            high_line = (mean_ts + sd_ts)\n",
    "        \n",
    "            # Avoid error when there is only one dimensional TS\n",
    "            idx_axes = tuple([i,j]) if(dim_ts>1) else tuple([i])\n",
    "\n",
    "            # Plots\n",
    "            axes[idx_axes].plot(mean_ts, colors[j], linewidth=2)\n",
    "            axes[idx_axes].fill_between(mean_ts.index, low_line, high_line, color=colors[j], alpha=0.2)\n",
    "\n",
    "            # axes = plt.subplot(gs[i, j])\n",
    "            # axes.plot(mean_ts, colors[j], linewidth=1)\n",
    "            # axes.fill_between(mean_ts.index, low_line, high_line, color=colors[j], alpha=0.3)\n",
    "            # axes.set(ylim=(-1,1))\n",
    "            axes[idx_axes].set_xticklabels([])\n",
    "            axes[idx_axes].grid(True)\n",
    "            # axes.set_yticklabels([])\n",
    "\n",
    "            # Set column labels\n",
    "            if(i == 0): axes[idx_axes].set_title(str('Dimension: ' + t_axis), fontsize=12)\n",
    "            if(j == 0): axes[idx_axes].set_ylabel(str('Class:' + str(t_class)))\n",
    "    \n",
    "    # plt.text(0.02, 0.98, \"Quaternion\", fontsize=14, ha=\"center\", va=\"center\", bbox = dict(boxstyle=\"darrow\",\n",
    "    #                                                                                             ec=\"k\",\n",
    "    #                                                                                             fc=(0.1,0.1,0.1,0),\n",
    "    #                                                                                             alpha=0.5,\n",
    "    #                                                                                             zorder=-5)\n",
    "    #                                                                                             )\n",
    "\n",
    "    if(save_path is not None):\n",
    "        if not os.path.isdir(os.path.dirname(save_path)):\n",
    "            os.makedirs(os.path.dirname(save_path))\n",
    "        plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    # plt.suptitle(\"$\\mu \\pm \\sigma$ Motion Trajectories\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset_quaternion\n",
    "# num_ts, length_ts, num_dims = dataset.shape\n",
    "# ROLLING_WINDOW_PLOT = int(length_ts*0.02)\n",
    "\n",
    "# if(experiment_config.SHOW_PLOTS): plot_summary_ts(dataset, classes, \\\n",
    "#                     rolling_window_size=ROLLING_WINDOW_PLOT, \\\n",
    "#                     axes_labels=[\"$q_w$\",\"$q_i$\",\"$q_j$\",\"$q_k$\"], \\\n",
    "#                     colors=['k','r','g','b'], \\\n",
    "#                     figsize=(2.5,1.8), \\\n",
    "#                     save_path=gen_path_plot(\"results_quaternion_traject\", extension=\".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([dataset_quaternion, dataset_euler/np.pi], axis=-1)\n",
    "num_ts, length_ts, num_dims = dataset.shape\n",
    "ROLLING_WINDOW_PLOT = int(length_ts*0.02)\n",
    "\n",
    "if(experiment_config.SHOW_PLOTS): plot_summary_ts(dataset, classes, \\\n",
    "                    rolling_window_size=ROLLING_WINDOW_PLOT, \\\n",
    "                    axes_labels=[\"$q_w$\",\"$q_i$\",\"$q_j$\",\"$q_k$\", \"Yaw $\\psi/\\pi$\",\"Pitch $\\\\theta/\\pi$\",\"Roll $\\phi/\\pi$\"], \\\n",
    "                    colors=['k','r','g','b','m','y','c'], \\\n",
    "                    figsize=(2.2,1.2), \\\n",
    "                    save_path=gen_path_plot(\"results_all_traject\", extension=\".pdf\"))"
   ]
  },
  {
   "source": [
    "# Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## Critical Diagram"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEST CLASSIFIER AMONG ALL FOLDS OF TWO DATASETS, FOUR DATA REPRESENTATIONS\n",
    "\n",
    "data = df_results\n",
    "data = data[ data[\"classlabels\"] == \"videos\"]\n",
    "data = data.drop(columns = [\"fit_time\",\"score_time\",\"classlabels\", \"methodtype\"])\n",
    "data[\"datasetfold\"] = data.agg( lambda x: f\"{x['datatype']}{x['dataset']}{x['fold']}\", axis=1 )\n",
    "data = data.drop(columns = [\"datatype\",\"dataset\",\"fold\"])\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "\n",
    "filename = gen_path_plot(\"critdiff_f1score\", extension=\".pdf\")\n",
    "criticaldiff_diagram = draw_cd_diagram(df_perf=data, title=None, labels=True, img_filepath=filename, classifier_colname = \"classifier\", dataset_colname=\"datasetfold\", performance_colname=\"test_f1_macro\", plot_width=7, plot_textspace=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEST CLASSIFIER PER DATASET AMONG ALL DATA REPRESENTATIONS AND FOLDS\n",
    "\n",
    "for d_dtset in [\"IMT\",\"Tsinghua\"]:\n",
    "    data = df_results\n",
    "    data = data[ data[\"dataset\"] == d_dtset]\n",
    "    data = data[ data[\"classlabels\"] == \"videos\"]\n",
    "    data = data.drop(columns = [\"fit_time\",\"score_time\",\"classlabels\", \"methodtype\",\"dataset\"])\n",
    "    data[\"datasetfold\"] = data.agg( lambda x: f\"{x['datatype']}{x['fold']}\", axis=1 )\n",
    "    data = data.drop(columns = [\"datatype\",\"fold\"])\n",
    "    print(data.shape)\n",
    "    print(data.head())\n",
    "\n",
    "    filename = gen_path_plot(\"critdiff_f1score_\"+d_dtset, extension=\".pdf\")\n",
    "    criticaldiff_diagram = draw_cd_diagram(df_perf=data, title=None, labels=True, img_filepath=filename, classifier_colname = \"classifier\", dataset_colname=\"datasetfold\", performance_colname=\"test_f1_macro\", plot_width=8, plot_textspace=1.5)"
   ]
  },
  {
   "source": [
    "---\n",
    "## Table sumarizing performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.head()\n",
    "\n",
    "data = df_results\n",
    "data = data[ data[\"classlabels\"]==\"videos\" ]\n",
    "data = data.drop(columns=[\"fit_time\",\"score_time\",\"test_accuracy\",\"test_precision_macro\",\"test_recall_macro\",\"classlabels\",\"fold\"])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"methodtype\"] = data[\"methodtype\"].map({\"fbc\":\"Feature-based classifiers\", \"tsc\":\"Time-series classifiers\"})\n",
    "d = data.groupby( [\"datatype\",\"dataset\",\"methodtype\",\"classifier\"] ).mean()\n",
    "d = d.unstack([\"methodtype\",\"classifier\"])\n",
    "d"
   ]
  },
  {
   "source": [
    "---\n",
    "## Line plot summarizing times to fit-predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_results\n",
    "data = data[ data[\"classlabels\"]==\"videos\" ]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together the time to train and fit one fold\n",
    "data[\"time\"] = data[\"fit_time\"] + data[\"score_time\"]\n",
    "\n",
    "# Drop unneeded columns\n",
    "data = data.drop(columns=[\"test_accuracy\",\"test_f1_macro\",\"test_precision_macro\",\"test_recall_macro\",\"methodtype\",\"classlabels\", \"fit_time\",\"score_time\",\"fold\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average time per classifier, dataype, dataset\n",
    "data = data.groupby( [\"datatype\",\"dataset\",\"classifier\"] ).mean()\n",
    "data = data.unstack(\"classifier\")\n",
    "data = data.reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the datasets\n",
    "M_imt=290; M_tsg=432\n",
    "N_imt=901; N_tsg=3601\n",
    "P_yaw=1; P_eul=3; P_quat=4; P_all=P_quat+P_eul\n",
    "\n",
    "# dict_mapping = {\n",
    "#     (\"All\",\"IMT\"):          M_imt * N_imt * P_all,\n",
    "#     (\"Quaternion\",\"IMT\"):   M_imt * N_imt * P_quat,\n",
    "#     (\"Euler\",\"IMT\"):        M_imt * N_imt * P_eul,\n",
    "#     (\"Yaw\",\"IMT\"):          M_imt * N_imt * P_yaw,\n",
    "#     (\"All\",\"Tsinghua\"):          M_tsg * N_tsg * P_all,\n",
    "#     (\"Quaternion\",\"Tsinghua\"):   M_tsg * N_tsg * P_quat,\n",
    "#     (\"Euler\",\"Tsinghua\"):        M_tsg * N_tsg * P_eul,\n",
    "#     (\"Yaw\",\"Tsinghua\"):          M_tsg * N_tsg * P_yaw,\n",
    "# }\n",
    "\n",
    "dict_mapping = {\n",
    "    (\"All\",\"IMT\"):          N_imt *  P_all,\n",
    "    (\"Quaternion\",\"IMT\"):   N_imt *  P_quat,\n",
    "    (\"Euler\",\"IMT\"):        N_imt *  P_eul,\n",
    "    (\"Yaw\",\"IMT\"):          N_imt *  P_yaw,\n",
    "    (\"All\",\"Tsinghua\"):          N_tsg * P_all,\n",
    "    (\"Quaternion\",\"Tsinghua\"):   N_tsg * P_quat,\n",
    "    (\"Euler\",\"Tsinghua\"):        N_tsg * P_eul,\n",
    "    (\"Yaw\",\"Tsinghua\"):          N_tsg * P_yaw,\n",
    "}\n",
    "dict_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data size that was used for the train,test split.\n",
    "datasize = []\n",
    "for (t,d) in zip(data[\"datatype\"],data[\"dataset\"]):\n",
    "    datasize.append( dict_mapping[(t,d)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final arrays for plotting\n",
    "data = data[\"time\"] # Keep only times\n",
    "\n",
    "# Add the size of dataset as index\n",
    "datasize = np.array(datasize)\n",
    "data.index = datasize\n",
    "data.sort_index(inplace=True)\n",
    "data.columns = [\"KNN\",\"DT\",\"RF\",\"GBM\",\"1NN-DTW\",\"MiniRocket\",\"ROCKET\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 5))\n",
    "markers = [\"*\",\"x\",\"+\",\"v\",\">\",\"D\",\"s\"]\n",
    "\n",
    "for i,c in enumerate(data.columns):\n",
    "    axes.plot(data.index, data[c], markers[i]+\"-\", label=c)\n",
    "    # axes.set_xscale(\"log\")\n",
    "    axes.set_yscale(\"log\")\n",
    "    axes.set_title(\"Time to train-fit one fold\")\n",
    "\n",
    "axes.legend()"
   ]
  },
  {
   "source": [
    "## Scaled training time vs accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_results\n",
    "data = data[ data[\"classlabels\"]==\"videos\" ]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together the time to train and fit one fold\n",
    "data = data.rename(columns={\"datatype\": \"repr.\",\"test_f1_macro\":\"f1_score\"})\n",
    "data[\"time\"] = data[\"fit_time\"] + data[\"score_time\"]\n",
    "\n",
    "# Drop unneeded columns\n",
    "data = data.drop(columns=[\"test_accuracy\",\"test_precision_macro\",\"test_recall_macro\",\"methodtype\",\"classlabels\", \"fit_time\",\"score_time\",\"fold\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average time per classifier, dataype, dataset\n",
    "data = data.groupby( [\"repr.\",\"dataset\",\"classifier\"] ).mean()\n",
    "data = data.unstack(\"classifier\")\n",
    "# data = data.reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values with respect to the performance and time of ROCKET\n",
    "data_scaled = data\n",
    "#data_scaled[\"f1_score\"] = data_scaled[\"f1_score\"] / \n",
    "\n",
    "for group in [\"f1_score\", \"time\"]:\n",
    "    for c in data_scaled[group].columns:\n",
    "        data_scaled[group][c] = data_scaled[group][c].values / data_scaled[group][\"ROCKET\"].values.copy()\n",
    "\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to wide format\n",
    "data_scaled = data_scaled.stack(\"classifier\").reset_index()\n",
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set(rc={\"figure.figsize\":(7,4)})\n",
    "\n",
    "# Scatter plot\n",
    "hue_order = [\"KNN\",\"DT\",\"RF\",\"GBM\",\"1NN-DTW\",\"MiniRocket\",\"ROCKET\"]\n",
    "ax = sns.scatterplot(data=data_scaled, x=\"time\", y=\"f1_score\", hue=\"classifier\", style=\"dataset\", hue_order=hue_order, s=80)\n",
    "ax.axvline(x=1, c=\"gray\", linestyle=\"--\", linewidth=2)\n",
    "ax.axhline(y=1, c=\"gray\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Texts\n",
    "ax.text(x=0.02, y=1.21, c=\"dimgray\", s=\"Faster and more accurate\")\n",
    "ax.text(x=4.5, y=1.21, c=\"dimgray\", s=\"Slower but more accurate\")\n",
    "ax.text(x=0.02, y=0.35, c=\"dimgray\", s=\"Faster but less accurate\")\n",
    "ax.text(x=4.5, y=0.35, c=\"dimgray\", s=\"Slower and less accurate\")\n",
    "ax.annotate(\"Proposed method\\n with ROCKET\", xy=(1,1), xytext=(0.07,1.07), c=\"black\", arrowprops=dict(arrowstyle=\"fancy\", fc=\"k\", ec=\"k\"))\n",
    "\n",
    "# Details\n",
    "ax.set_ylim([0.3,1.3])\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Scaled training time\")\n",
    "ax.set_ylabel(\"Scaled performance (f1-score)\")\n",
    "# plt.title(\"Training times\")\n",
    "plt.legend(bbox_to_anchor=(0.12, -0.2), loc='upper left', borderaxespad=0, ncol=3)\n",
    "\n",
    "filename = gen_path_plot(\"scatterplot_trainingtimes\", extension=\".pdf\")\n",
    "plt.savefig(filename, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "---\n",
    "\n",
    "All plots in a single image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style(\"ticks\")\n",
    "\n",
    "# mc_iter = experiment_config.MC_ITERATIONS\n",
    "\n",
    "# rows_plot=3\n",
    "# cols_plot=2\n",
    "# y_lim = [0,1]\n",
    "# figsize=(5,4)\n",
    "# save_path = gen_path_plot(f\"compiled_results_2\",extension=\".pdf\") # None\n",
    "\n",
    "# fig, axes = plt.subplots(rows_plot, cols_plot, figsize=(figsize[0]*cols_plot, figsize[1]*rows_plot), sharex=False, sharey=False)\n",
    "# ax_idx = 0\n",
    "# try:\n",
    "#     axes = axes.T.flatten() #axes.flatten()\n",
    "# except Exception as e: # Only one axis\n",
    "#     axes = [axes]\n",
    "\n",
    "# ############################### ###############################\n",
    "# ############################### IMT ###############################\n",
    "# ############################### ###############################\n",
    "# dataset_text = \"IMT\" #\"IMT\" # \"Tsinghua\"\n",
    "# dataframe = IMT_results #IMT_results #TSI_results\n",
    "\n",
    "\n",
    "# # Plot per axis\n",
    "# data = dataframe #### DATA TO PLOT\n",
    "# data = data[ data[\"classLabel\"]==1 ]\n",
    "# x_colname = \"classifier\"\n",
    "# y_colname = \"accuracy\"\n",
    "# hue_colname = \"dataRep\"\n",
    "# ax = axes[ax_idx]; ax_idx=ax_idx+1\n",
    "\n",
    "# # Plot\n",
    "# ax = sns.boxplot(ax=ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, linewidth=0.5)\n",
    "# # Statistical tests\n",
    "# box_pairs = [\n",
    "#     ((\"1-NN\",\"Quaternion(4D)\"),(\"1-NN\",\"Euler(3D)\")),\n",
    "#     ((\"1-NN\",\"Euler(3D)\"),(\"1-NN\",\"Spherical(2D)\")),\n",
    "#     ((\"1-NN\",\"Spherical(2D)\"),(\"1-NN\",\"Yaw(1D)\")),\n",
    "#     ((\"7-NN\",\"Quaternion(4D)\"),(\"7-NN\",\"Euler(3D)\")),\n",
    "#     ((\"7-NN\",\"Euler(3D)\"),(\"7-NN\",\"Spherical(2D)\")),\n",
    "#     ((\"7-NN\",\"Spherical(2D)\"),(\"7-NN\",\"Yaw(1D)\")),\n",
    "# ]\n",
    "# ax, test_results = add_stat_annotation(ax, data=data, x=x_colname, y=y_colname, hue=hue_colname,#order=order,\n",
    "#                                    box_pairs=box_pairs,\n",
    "#                                    test='t-test_ind', text_format='star', loc='inside', verbose=2,\n",
    "#                                    stats_params=dict(alternative=\"greater\"))\n",
    "\n",
    "# if(y_lim is not None):\n",
    "#     ax.set_ylim(tuple(y_lim))\n",
    "# ax.set(title=f\"Dataset {dataset_text} | Results per data representation\", xlabel=x_colname, ylabel=y_colname)\n",
    "# ax.grid(True)\n",
    "\n",
    "\n",
    "# ###############################\n",
    "# # Plot per axis\n",
    "# data = dataframe #### DATA TO PLOT\n",
    "# data = data[ data[\"classLabel\"]==1 ]\n",
    "\n",
    "# x_colname = \"dataRep\"\n",
    "# y_colname = \"accuracy\"\n",
    "# hue_colname = \"classifier\"\n",
    "# ax = axes[ax_idx]; ax_idx=ax_idx+1\n",
    "\n",
    "# # Plot\n",
    "# ax = sns.boxplot(ax=ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, linewidth=0.5, palette=\"Spectral\")\n",
    "# # Statistical tests\n",
    "# box_pairs = [\n",
    "#     ((\"Quaternion(4D)\",\"1-NN\"),(\"Quaternion(4D)\",\"7-NN\")),\n",
    "#     ((\"Euler(3D)\",\"1-NN\"),(\"Euler(3D)\",\"7-NN\")),\n",
    "#     ((\"Spherical(2D)\",\"1-NN\"),(\"Spherical(2D)\",\"7-NN\")),\n",
    "#     ((\"Yaw(1D)\",\"1-NN\"),(\"Yaw(1D)\",\"7-NN\")),\n",
    "# ]\n",
    "# ax, test_results = add_stat_annotation(ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, #order=order,\n",
    "#                                    box_pairs=box_pairs,\n",
    "#                                    test='t-test_ind', text_format='star', loc='inside', verbose=2,\n",
    "#                                    stats_params=dict(alternative=\"less\"))\n",
    "\n",
    "# if(y_lim is not None):\n",
    "#     ax.set_ylim(tuple(y_lim))\n",
    "# ax.set(title=f\"Dataset {dataset_text} | Results per classifier\", xlabel=x_colname, ylabel=y_colname)\n",
    "# ax.grid(True)\n",
    "\n",
    "# ###############################\n",
    "# # Plot per axis\n",
    "# data = dataframe #### DATA TO PLOT\n",
    "# data = data[data[\"classLabel\"]==1]\n",
    "# data = data[ data[\"distMetric\"]!=0 ]\n",
    "# data = data[ data[\"classifier\"]==\"7-NN\" ]\n",
    "# x_colname = \"dataRep\"\n",
    "# y_colname = \"accuracy\"\n",
    "# hue_colname = \"distMetric\"\n",
    "# ax = axes[ax_idx]; ax_idx=ax_idx+1\n",
    "\n",
    "# # Plot\n",
    "# ax = sns.boxplot(ax=ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, linewidth=0.5, palette=\"Set2\")\n",
    "# # Statistical tests\n",
    "# box_pairs = [\n",
    "#     ((\"Quaternion(4D)\",\"Euclidean\"),(\"Quaternion(4D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Quaternion(4D)\",\"Spec_Eucl\"),(\"Quaternion(4D)\",\"DTW\")),\n",
    "#     ((\"Euler(3D)\",\"Euclidean\"),(\"Euler(3D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Euler(3D)\",\"Spec_Eucl\"),(\"Euler(3D)\",\"DTW\")),\n",
    "#     ((\"Spherical(2D)\",\"Euclidean\"),(\"Spherical(2D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Spherical(2D)\",\"Spec_Eucl\"),(\"Spherical(2D)\",\"DTW\")),\n",
    "#     ((\"Yaw(1D)\",\"Euclidean\"),(\"Yaw(1D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Yaw(1D)\",\"Spec_Eucl\"),(\"Yaw(1D)\",\"DTW\")),\n",
    "# ]\n",
    "# ax, test_results = add_stat_annotation(ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, #order=order,\n",
    "#                                    box_pairs=box_pairs,\n",
    "#                                    test='t-test_ind', text_format='star', loc='inside', verbose=2,\n",
    "#                                    stats_params=dict(alternative=\"less\"))\n",
    "\n",
    "# if(y_lim is not None):\n",
    "#     ax.set_ylim(tuple(y_lim))\n",
    "# ax.set(title=f\"Dataset {dataset_text} | Results per distance metric in 7-NN\", xlabel=x_colname, ylabel=y_colname)\n",
    "# ax.grid(True)\n",
    "\n",
    "# ############################### ###############################\n",
    "# ############################### TSINGHUA ###############################\n",
    "# ############################### ###############################\n",
    "# dataset_text = \"Tsinghua\" #\"IMT\" # \"Tsinghua\"\n",
    "# dataframe = TSI_results #IMT_results #TSI_results\n",
    "\n",
    "# # Plot per axis\n",
    "# data = dataframe #### DATA TO PLOT\n",
    "# data = data[ data[\"classLabel\"]==1 ]\n",
    "# x_colname = \"classifier\"\n",
    "# y_colname = \"accuracy\"\n",
    "# hue_colname = \"dataRep\"\n",
    "# ax = axes[ax_idx]; ax_idx=ax_idx+1\n",
    "\n",
    "# # Plot\n",
    "# ax = sns.boxplot(ax=ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, linewidth=0.5)\n",
    "# # Statistical tests\n",
    "# box_pairs = [\n",
    "#     ((\"1-NN\",\"Quaternion(4D)\"),(\"1-NN\",\"Euler(3D)\")),\n",
    "#     ((\"1-NN\",\"Euler(3D)\"),(\"1-NN\",\"Spherical(2D)\")),\n",
    "#     ((\"1-NN\",\"Spherical(2D)\"),(\"1-NN\",\"Yaw(1D)\")),\n",
    "#     ((\"11-NN\",\"Quaternion(4D)\"),(\"11-NN\",\"Euler(3D)\")),\n",
    "#     ((\"11-NN\",\"Euler(3D)\"),(\"11-NN\",\"Spherical(2D)\")),\n",
    "#     ((\"11-NN\",\"Spherical(2D)\"),(\"11-NN\",\"Yaw(1D)\")),\n",
    "# ]\n",
    "# ax, test_results = add_stat_annotation(ax, data=data, x=x_colname, y=y_colname, hue=hue_colname,#order=order,\n",
    "#                                    box_pairs=box_pairs,\n",
    "#                                    test='t-test_ind', text_format='star', loc='inside', verbose=2,\n",
    "#                                    stats_params=dict(alternative=\"greater\"))\n",
    "\n",
    "# if(y_lim is not None):\n",
    "#     ax.set_ylim(tuple(y_lim))\n",
    "# ax.set(title=f\"Dataset {dataset_text} | Results per data representation\", xlabel=x_colname, ylabel=y_colname)\n",
    "# ax.grid(True)\n",
    "\n",
    "\n",
    "# ###############################\n",
    "# # Plot per axis\n",
    "# data = dataframe #### DATA TO PLOT\n",
    "# data = data[ data[\"classLabel\"]==1 ]\n",
    "# x_colname = \"dataRep\"\n",
    "# y_colname = \"accuracy\"\n",
    "# hue_colname = \"classifier\"\n",
    "# ax = axes[ax_idx]; ax_idx=ax_idx+1\n",
    "\n",
    "# # Plot\n",
    "# ax = sns.boxplot(ax=ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, linewidth=0.5, palette=\"Spectral\")\n",
    "# # Statistical tests\n",
    "# box_pairs = [\n",
    "#     ((\"Quaternion(4D)\",\"1-NN\"),(\"Quaternion(4D)\",\"11-NN\")),\n",
    "#     ((\"Euler(3D)\",\"1-NN\"),(\"Euler(3D)\",\"11-NN\")),\n",
    "#     ((\"Spherical(2D)\",\"1-NN\"),(\"Spherical(2D)\",\"11-NN\")),\n",
    "#     ((\"Yaw(1D)\",\"1-NN\"),(\"Yaw(1D)\",\"11-NN\")),\n",
    "# ]\n",
    "# ax, test_results = add_stat_annotation(ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, #order=order,\n",
    "#                                    box_pairs=box_pairs,\n",
    "#                                    test='t-test_ind', text_format='star', loc='inside', verbose=2,\n",
    "#                                    stats_params=dict(alternative=\"less\"))\n",
    "\n",
    "# if(y_lim is not None):\n",
    "#     ax.set_ylim(tuple(y_lim))\n",
    "# ax.set(title=f\"Dataset {dataset_text} | Distance metric in classifier\", xlabel=x_colname, ylabel=y_colname)\n",
    "# ax.grid(True)\n",
    "\n",
    "# ###############################\n",
    "# # Plot per axis\n",
    "# data = dataframe #### DATA TO PLOT\n",
    "# data = data[data[\"classLabel\"]==1]\n",
    "# data = data[ data[\"distMetric\"]!=0 ]\n",
    "# data = data[ data[\"classifier\"]==\"11-NN\" ]\n",
    "# x_colname = \"dataRep\"\n",
    "# y_colname = \"accuracy\"\n",
    "# hue_colname = \"distMetric\"\n",
    "# ax = axes[ax_idx]; ax_idx=ax_idx+1\n",
    "\n",
    "# # Plot\n",
    "# ax = sns.boxplot(ax=ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, linewidth=0.5, palette=\"Set2\")\n",
    "# # Statistical tests\n",
    "# box_pairs = [\n",
    "#     ((\"Quaternion(4D)\",\"Euclidean\"),(\"Quaternion(4D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Quaternion(4D)\",\"Spec_Eucl\"),(\"Quaternion(4D)\",\"DTW\")),\n",
    "#     ((\"Euler(3D)\",\"Euclidean\"),(\"Euler(3D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Euler(3D)\",\"Spec_Eucl\"),(\"Euler(3D)\",\"DTW\")),\n",
    "#     ((\"Spherical(2D)\",\"Euclidean\"),(\"Spherical(2D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Spherical(2D)\",\"Spec_Eucl\"),(\"Spherical(2D)\",\"DTW\")),\n",
    "#     ((\"Yaw(1D)\",\"Euclidean\"),(\"Yaw(1D)\",\"Spec_Eucl\")),\n",
    "#     ((\"Yaw(1D)\",\"Spec_Eucl\"),(\"Yaw(1D)\",\"DTW\")),\n",
    "# ]\n",
    "# ax, test_results = add_stat_annotation(ax, data=data, x=x_colname, y=y_colname, hue=hue_colname, #order=order,\n",
    "#                                    box_pairs=box_pairs,\n",
    "#                                    test='t-test_ind', text_format='star', loc='inside', verbose=2,\n",
    "#                                    stats_params=dict(alternative=\"less\"))\n",
    "\n",
    "# if(y_lim is not None):\n",
    "#     ax.set_ylim(tuple(y_lim))\n",
    "# ax.set(title=f\"Dataset {dataset_text} | Results per distance metric in 11-NN\", xlabel=x_colname, ylabel=y_colname)\n",
    "# ax.grid(True)\n",
    "\n",
    "# ###############################\n",
    "# # Figure setup\n",
    "# # fig.suptitle(f'Classification results over {mc_iter} Monte-Carlo simulations')\n",
    "# # fig.subplots_adjust(bottom=0.25, wspace=0.08)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# if(save_path is not None):\n",
    "#     if not os.path.isdir(os.path.dirname(save_path)):\n",
    "#         os.makedirs(os.path.dirname(save_path))\n",
    "#     plt.savefig(save_path, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "source": [
    "## EOF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> FINISHED WITHOUT ERRORS!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}